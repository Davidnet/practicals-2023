{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2s4kN_QPQVe"
      },
      "source": [
        "# Jax, Optax, Haiku and Convolutional Neural Networks\n",
        "\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/khipu-ai/practicals-2023/blob/main/notebooks/jax_optax_haiku_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "## Copyright\n",
        "\n",
        "* Deep Learning Indaba 2022. Apache License 2.0.\n",
        "* Khipu 2023. Apache License 2.0.\n",
        "\n",
        "## Authors\n",
        "\n",
        "* Kale-ab Tessera (Indaba 2022)\n",
        "* Ignacio RamÃ­rez (Khipu 2023)\n",
        "\n",
        "## Reviewers\n",
        "* Javier Antoran\n",
        "* James Allingham\n",
        "* Ruan van der Merwe\n",
        "* Sebastian Bodenstein\n",
        "* Laurence Midgley\n",
        "* Joao Guilherme\n",
        "* Elan van Biljon\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "We begin by introducing JAX. JAX is a library that allows for very efficient speedups in the aforementioned operations by transparently choosing the best available hardware (CPU, GPU, TPU, etc.) and provinding with a number of acceleration and automation mechanisms such as automatic differentiation (`grad`), parallelization (`pmap`), vectorization (`vmap`) and just-in-time compilation (`jit`).\n",
        "\n",
        "We will then show you how to use the [Optax](https://github.com/deepmind/optax) library, an efficient optimization library based on JAX.\n",
        "\n",
        "We'll then show you how to use  [Haiku](https://github.com/deepmind/dm-haiku),  for building and training neural networks.\n",
        "\n",
        "\n",
        "## Topics\n",
        "\n",
        "* Accelerated computation with JAX\n",
        "* Optimization with Optax\n",
        "* Model training with Haiku\n",
        "* Training a Convolutional Neural Network with Haiku\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "This practical assumes that you are familiar with:\n",
        "* Python and NumPy\n",
        "* Basic object oriented programming\n",
        "* Basic optimization (gradient descent, etc.)\n",
        "* Basic model learning (linear models)\n",
        "\n",
        "## Hardware requirements (**important**)\n",
        "\n",
        "For this practical, you will need to use a GPU to speed up training. To do this, go to the \"Runtime\" menu in Colab, select \"Change runtime type\" and then in the popup menu, choose \"GPU\" in the \"Hardware accelerator\" box.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EqhIg1odqg0"
      },
      "source": [
        "## Installation and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4boGA9rYdt9l",
        "outputId": "8969703c-6638-45e6-f43a-fef1b4d2ba2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a GPU is connected.\n"
          ]
        }
      ],
      "source": [
        "## Install and import anything required. Capture hides the output from the cell.\n",
        "# @title Install and import required packages. (Run Cell)\n",
        "\n",
        "import os\n",
        "\n",
        "# https://stackoverflow.com/questions/68340858/in-google-colab-is-there-a-programing-way-to-check-which-runtime-like-gpu-or-tpu\n",
        "if int(os.environ[\"COLAB_GPU\"]) > 0:\n",
        "    print(\"a GPU is connected.\")\n",
        "elif \"COLAB_TPU_ADDR\" in os.environ and os.environ[\"COLAB_TPU_ADDR\"]:\n",
        "    print(\"A TPU is connected.\")\n",
        "    import jax.tools.colab_tpu\n",
        "\n",
        "    jax.tools.colab_tpu.setup_tpu()\n",
        "else:\n",
        "    print(\"Only CPU accelerator is connected.\")\n",
        "    # x8 cpu devices - number of (emulated) host devices\n",
        "    os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count=8\"\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap, pmap\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YQe1CfDyrkdL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Helper Functions. (Run Cell)\n",
        "import copy\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "def plot_performance(data: Dict, title: str):\n",
        "    runs = list(data.keys())\n",
        "    time = list(data.values())\n",
        "\n",
        "    # creating the bar plot\n",
        "    plt.bar(runs, time, width=0.35)\n",
        "\n",
        "    plt.xlabel(\"Implementation\")\n",
        "    plt.ylabel(\"Average time taken (in s)\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "    best_perf_key = min(data, key=data.get)\n",
        "    all_runs_key = copy.copy(runs)\n",
        "\n",
        "    # all_runs_key_except_best\n",
        "    all_runs_key.remove(best_perf_key)\n",
        "\n",
        "    for k in all_runs_key:\n",
        "        print(\n",
        "            f\"{best_perf_key} was {round((data[k]/data[best_perf_key]),2)} times faster than {k} !!!\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yFzjRHUsUQqq",
        "cellView": "form",
        "outputId": "c7b04f1d-0ada-451d-fd1b-3ca73491afe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num devices: 1\n",
            " Devices: [GpuDevice(id=0, process_index=0)]\n"
          ]
        }
      ],
      "source": [
        "# @title Check the device you are using (Run Cell)\n",
        "print(f\"Num devices: {jax.device_count()}\")\n",
        "print(f\" Devices: {jax.devices()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\newcommand{\\because}[1]{&& \\triangleright \\textrm{#1}}\n",
        "$$"
      ],
      "metadata": {
        "id": "blMNBku0dB8h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbOEYsWQ6tHv"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# PART 1 - JAX\n",
        "\n",
        "<hr>\n",
        "\n",
        "## Similarities between JAX and NumPy \n",
        "\n",
        "The main similarity between JAX and NumPy is that they share a similar interface and often, JAX and NumPy arrays can be used interchangeably.The code below shows this. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sgRLq58OTz1t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a2067cfd-bf00-4f21-a7fa-ae25c386b0bb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#@title Using NumPy\n",
        "\n",
        "# 100 linearly spaced numbers from -np.pi to np.pi\n",
        "x = np.linspace(-np.pi, np.pi, 100)\n",
        "\n",
        "# the function, which is y = sin(x) here\n",
        "y = np.sin(x)\n",
        "\n",
        "# plot the functions\n",
        "plt.plot(x, y, \"b\", label=\"y=sin(x)\")\n",
        "\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kRQf2mNRTlt3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "10e39819-316f-4dd1-ea21-7dd42720fd48"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#@title using JAX\n",
        "# 100 linearly spaced numbers from -jnp.pi to jnp.pi\n",
        "x = jnp.linspace(-jnp.pi, jnp.pi, 100)\n",
        "\n",
        "# the function, which is y = sin(x) here\n",
        "y = jnp.sin(x)\n",
        "\n",
        "# plot the functions\n",
        "plt.plot(x, y, \"b\", label=\"y=sin(x)\")\n",
        "\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuNscwHeV_dn"
      },
      "source": [
        "**Exercise 1.1 - Code Task:** Can you plot the cosine function using `jnp`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5svZFPUCQNsG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2112b6ff-cde8-4cef-a1ee-ace955bad306"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#@title Excercise 1.1\n",
        "#\n",
        "# Plot Cosine using jnp\n",
        "\n",
        "# 100 linearly spaced numbers\n",
        "\n",
        "x = jnp.linspace(-jnp.pi, jnp.pi, 100)\n",
        "\n",
        "# the function, which is y = sin(x) here\n",
        "y = jnp.cos(x)\n",
        "\n",
        "#\n",
        "# plot the functions\n",
        "#\n",
        "plt.plot(x, y, \"b\", label=\"y=cos(x)\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "m4AVrGzy6JWR",
        "cellView": "form",
        "outputId": "b9e31e42-78eb-42d5-c12b-48e7ef00f354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# @title Answer to code task (Try not to peek until you've given it a good try!')\n",
        "# 100 linearly spaced numbers\n",
        "x = jnp.linspace(-jnp.pi, jnp.pi, 100)\n",
        "\n",
        "y = jnp.cos(x)\n",
        "\n",
        "# plot the functions\n",
        "plt.plot(x, y, \"b\", label=\"y=cos(x)\")\n",
        "\n",
        "plt.legend(loc=\"upper left\")\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg4__l4A7yqc"
      },
      "source": [
        "## Differences between JAX and NumPy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPbOnhE4ZSTi"
      },
      "source": [
        "### JAX arrays are immutable, NumPy arrays are not\n",
        "\n",
        "JAX and NumPy arrays are often interchangeable, **but** Jax arrays are **immutable** (they can't be modified after they are created). Allowing mutations makes transforms difficult and violates conditions for [pure functions](https://en.wikipedia.org/wiki/Pure_function).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy\n",
        "\n",
        "Let's see this in practice by changing the number at the beginning of an array. "
      ],
      "metadata": {
        "id": "Vdfb1wtd-GkF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7r-Los6YZR-f",
        "outputId": "2d88833f-5150-4bd1-83ae-f3d0e8944829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10  1  2  3  4  5  6  7  8  9]\n"
          ]
        }
      ],
      "source": [
        "# NumPy: mutable arrays\n",
        "x = np.arange(10)\n",
        "x[0] = 10\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JAX"
      ],
      "metadata": {
        "id": "8Y23OWjE_BDA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OxjkKpqAZxWo",
        "outputId": "2f3f6598-5212-402b-8f21-1d13b450a307",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception '<class 'jaxlib.xla_extension.DeviceArray'>' object does not support item assignment. JAX arrays are immutable. Instead of ``x[idx] = y``, use ``x = x.at[idx].set(y)`` or another .at[] method: https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html\n"
          ]
        }
      ],
      "source": [
        "# JAX: immutable arrays\n",
        "# Should raise an error.\n",
        "try:\n",
        "    x = jnp.arange(10)\n",
        "    x[0] = 10\n",
        "except Exception as e:\n",
        "    print(\"Exception {}\".format(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoWT5RBUagW8"
      },
      "source": [
        "So it fails! We can't mutate a JAX array once it has been created. To update JAX arrays, we need to use [helper functions](https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.ndarray.at.html) that return an updated copy of the JAX array. \n",
        "\n",
        "Instead of doing this `x[idx] = y`, we need to do this `x = x.at[idx].set(y)`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qJYxkh4qagwO",
        "outputId": "5a6ca0aa-1573-4bfe-c2e2-db16bb42230d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " new_x: [10  1  2  3  4  5  6  7  8  9] original x: [0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ],
      "source": [
        "x = jnp.arange(10)\n",
        "new_x = x.at[0].set(10)\n",
        "print(f\" new_x: {new_x} original x: {x}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut0meCGB5qD0"
      },
      "source": [
        "Note here that `new_x` is a copy and that the original `x` is unchanged. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAH4c_smdGQU"
      },
      "source": [
        "## Random number generation in NumPy and JAX \n",
        "\n",
        "JAX is more explicit in Pseudo Random Number Generation (PRNG) than `NumPy` and other libraries (such as `TensorFlow` or `PyTorch`). [PRNG](https://en.wikipedia.org/wiki/Pseudorandom_number_generator) is the process of algorithmically generating a sequence of numbers, which *approximate* the properties of a sequence of random numbers.  \n",
        "\n",
        "Let's see the differences in how JAX and NumPy generate random numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2m376Ethf8m"
      },
      "source": [
        "##### In Numpy, PRNG is based on a global `state`.\n",
        "\n",
        "Let's set the initial seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-0t3sjxzdgmP"
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "np.random.seed(42)\n",
        "prng_state = np.random.get_state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "QKVz5atZMMOV"
      },
      "outputs": [],
      "source": [
        "# @title Helper function to compare prng keys (Run Cell)\n",
        "def is_prng_state_the_same(prng_1, prng_2):\n",
        "    \"\"\"Helper function to compare two prng keys.\"\"\"\n",
        "    # concat all elements in prng tuple\n",
        "    list_prng_data_equal = [(a == b) for a, b in zip(prng_1, prng_2)]\n",
        "    # stack all elements together\n",
        "    list_prng_data_equal = np.hstack(list_prng_data_equal)\n",
        "    # check if all elements are the same\n",
        "    is_prng_equal = all(list_prng_data_equal)\n",
        "    return is_prng_equal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nloZ9abah3J3"
      },
      "source": [
        "Let's take a few samples from a Gaussian (normal) Distribution and check if PRNG keys/global state change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aiUcfX7iSenY",
        "outputId": "6410a90c-4bee-4daf-a2ca-f017526a9e42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample 1 = 0.4967141530112327 Did prng state change: True\n",
            "sample 2 = -0.13826430117118466 Did prng state change: True\n",
            "sample 3 = 0.6476885381006925 Did prng state change: True\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    f\"sample 1 = {np.random.normal()} Did prng state change: {not is_prng_state_the_same(prng_state,np.random.get_state())}\"\n",
        ")\n",
        "prng_state = np.random.get_state()\n",
        "print(\n",
        "    f\"sample 2 = {np.random.normal()} Did prng state change: {not is_prng_state_the_same(prng_state,np.random.get_state())}\"\n",
        ")\n",
        "prng_state = np.random.get_state()\n",
        "print(\n",
        "    f\"sample 3 = {np.random.normal()} Did prng state change: {not is_prng_state_the_same(prng_state,np.random.get_state())}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuHkW6V4iLa9"
      },
      "source": [
        "Numpy's global random state is updated every time a random number is generated, so *sample 1 != sample 2 != sample 3*. \n",
        "\n",
        "Having the state automatically updated, makes it difficult to handle randomness in a **reproducible** way across different threads, processes and devices. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGDU6ckKkzqL"
      },
      "source": [
        "##### In JAX, PRNG is explicit.\n",
        "\n",
        "In JAX, for each random number generation, you need to explicitly pass in a random key/state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oKdk5CSmD-f"
      },
      "source": [
        "Passing the same state/key results in the same number being generated. This is generally undesirable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Y-6B0hjtlTmd",
        "outputId": "64aa6d63-5d0f-4454-cdd0-0a7de08af12b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample 1 = -0.1847117692232132\n",
            "sample 2 = -0.1847117692232132\n",
            "sample 3 = -0.1847117692232132\n"
          ]
        }
      ],
      "source": [
        "from jax import random\n",
        "\n",
        "key = random.PRNGKey(42)\n",
        "print(f\"sample 1 = {random.normal(key)}\")\n",
        "print(f\"sample 2 = {random.normal(key)}\")\n",
        "print(f\"sample 3 = {random.normal(key)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0KcwEbZqIaQ"
      },
      "source": [
        "To generate different and independent samples, you need to manually **split** the keys. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "v-7BhY0MmEhI",
        "outputId": "cc047d01-495f-47c9-db50-d2361fd3c5cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample 1 = -0.1847117692232132\n",
            "sample 2 = 1.369469404220581\n",
            "sample 3 = -0.19947023689746857\n"
          ]
        }
      ],
      "source": [
        "from jax import random\n",
        "\n",
        "key = random.PRNGKey(42)\n",
        "print(f\"sample 1 = {random.normal(key)}\")\n",
        "\n",
        "# We split the key -> new key and subkey\n",
        "new_key, subkey = random.split(key)\n",
        "\n",
        "# We use the subkey immediately and keep the new key for future splits.\n",
        "# It doesn't really matter which key we keep and which one we use immediately.\n",
        "print(f\"sample 2 = {random.normal(subkey)}\")\n",
        "\n",
        "# We split the new key -> new key2 and subkey\n",
        "new_key2, subkey = random.split(new_key)\n",
        "print(f\"sample 3 = {random.normal(subkey)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VnTDptmuk-i"
      },
      "source": [
        "By using JAX, we can more easily reproduce random number generation in parallel across threads, processes, or even devices by explicitly passing and keeping track of the prng key (without relying on a global state that automatically gets updated). For more details on PRNG in JAX, you can read more [here](https://jax.readthedocs.io/en/latest/jep/263-prng.html). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSj972IWxTo2"
      },
      "source": [
        "### Acceleration in JAX ð\n",
        "\n",
        "JAX leverages Autograd and XLA for accelerating numerical computation. The use of Autograd allows for automatic differentiation (`grad`), while XLA allows JAX to run on multiple accelerators/backends and run transforms like `jit` and `pmap`. JAX also allows you to use `vmap` for automatic vectorization.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bQ9QqT-yKbs"
      },
      "source": [
        "### JAX is backend Agnostic\n",
        "\n",
        "Using JAX, you can run the same code on different backends/AI accelerators (e.g. CPU/GPU/TPU), **with no changes in code** (no more `.to(device)` - from frameworks like PyTorch). This means we can easily run linear algebra operations directly on GPU/TPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PbcFsfAibBu"
      },
      "source": [
        "**Multiplying Matrices**\n",
        "\n",
        "Dot products are a common operation in numerical computing and a central part of modern deep learning. They are defined over [vectors](https://en.wikipedia.org/wiki/Coordinate_vector), which can loosely be thought of as a list of multiple scalers (single values). \n",
        "\n",
        "Formally, given two vectors $\\boldsymbol{x}$,$\\boldsymbol{y}$ $\\in R^n$, their dot product is defined as:\n",
        "\n",
        "<center>$\\boldsymbol{x}^{\\top} \\boldsymbol{y}=\\sum_{i=1}^{n} x_{i} y_{i}$</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY1RsVkXaokP"
      },
      "source": [
        "Dot Product in NumPy (will run on cpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yj59KkD_HDOs",
        "outputId": "cab7de66-56c1-4075-ea93-f6d31c865fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67.7 ms Â± 26.8 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "size = 1000\n",
        "x = np.random.normal(size=(size, size))\n",
        "y = np.random.normal(size=(size, size))\n",
        "numpy_time = %timeit -o -n 10 a_np = np.dot(y,x.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c_kl-u0KPVY"
      },
      "source": [
        "Dot Product using JAX (will run on current runtime - e.g. GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PHRcHK86KO3w",
        "outputId": "857e41fc-c624-438b-87e1-8362bf4be6ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 255.54 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "48.3 ms Â± 115 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "size = 1000\n",
        "key1, key2 = jax.random.split(jax.random.PRNGKey(42), num=2)\n",
        "x = jax.random.normal(key1, shape=(size, size))\n",
        "y = jax.random.normal(key2, shape=(size, size))\n",
        "jax_time = %timeit -o -n 10 jnp.dot(y, x.T).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMTSpEG3TNah"
      },
      "source": [
        "\n",
        "> When timing JAX functions, we use `.block_until_ready()` because JAX uses [asynchronous dispatch](https://jax.readthedocs.io/en/latest/async_dispatch.html#async-dispatch). This means JAX doesn't wait for the operation to complete before returning control to your code. To fairly compute the time taken for JAX operations, we therefore block until the operation is done.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3vwh6Q724gn"
      },
      "source": [
        "How much faster was the dot product in JAX (Using GPU)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UkASX9p34A1D",
        "outputId": "010c62be-caf4-4698-9501-b4a314b9a4e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jax was 1.4 times faster than numpy !!!\n"
          ]
        }
      ],
      "source": [
        "np_average_time = np.mean(numpy_time.all_runs)\n",
        "jax_average_time = np.mean(jax_time.all_runs)\n",
        "data = {\"numpy\": np_average_time, \"jax\": jax_average_time}\n",
        "\n",
        "plot_performance(data, title=\"Average time taken per framework to run dot product\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "JAX not running much faster? -> Re-run the JAX cell.                       \n",
        "> \"Keep in mind that the first time you run JAX code, it will be slower because it is being compiled. T*his is true even if you donât use jit in your own code, because JAXâs builtin functions are also jit compiled*.\" - [JAX Docs](https://jax.readthedocs.io/en/latest/faq.html#benchmarking-jax-code).\n",
        "\n",
        "If you are running on an accelerator, you should see a considerable performance benefit of using JAX, without making any changes to your code! \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X6Rv_OQgBOqr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM_08mXEBRIK"
      },
      "source": [
        "# JAX Transformations\n",
        "\n",
        "JAX transforms (`jit`, `grad`, `vmap`, `pmap`) first convert python functions into an intermediate language called *jaxpr*. Transforms are then applied to this jaxpr representation.\n",
        "\n",
        "JAX generates jaxpr, in a process known as **tracing**. During tracing, function inputs are wrapped by a tracer object and then JAX records all operations (including regular python code) that occur during the function call. These recorded operations are used to reconstruct the function. \n",
        "\n",
        "Any python side-effects are not recorded during tracing. JAX transforms and compilations are designed to work only with **pure functions**. For more on tracing and jaxpr, you can read [here](https://jax.readthedocs.io/en/latest/jaxpr.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsJE_U-ZzVol"
      },
      "source": [
        "## JIT (Just in Time) compilation\n",
        "\n",
        "Jax dispatches operations to accelerators one at a time. If we have repeated operations, we can use `jit` to compile the function the first time it is called, then subsequent calls will be [cached](https://en.wikipedia.org/wiki/Cache_(computing) (save the compiled version so that it doesn't need to be recompiled everytime we call it). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIYsqIp_-Dly"
      },
      "source": [
        "Let's compile [ReLU (Rectified Linear Unit)](https://arxiv.org/abs/1803.08375), a popular activation function in deep learning. \n",
        "\n",
        "ReLU is defined as follows:\n",
        "<center>$f(x)=max(0,x)$</center>\n",
        "\n",
        "It can be visualized as follows:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/10/Line-Plot-of-Rectified-Linear-Activation-for-Negative-and-Positive-Inputs.png\" width=\"35%\" />\n",
        "</center>,\n",
        "\n",
        "where $x$ is the input to the function and $y$ is output of ReLU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm-bN9sQETLV"
      },
      "source": [
        "$$f(x)=\\max (0, x)=\\left\\{\\begin{array}{l}x_{i} \\text { if } x_{i}>0 \\\\ 0 \\text { if } x_{i}<=0\\end{array}\\right.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFiuu3BFAKdY"
      },
      "source": [
        "**Exercise 1.2 - Code Task:** Complete the ReLU implementation below using standard python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1_qMJJbs-Cbe"
      },
      "outputs": [],
      "source": [
        "# Implement ReLU.\n",
        "def relu(x):\n",
        "    if x > 0:\n",
        "        return\n",
        "        # TODO Implement me!\n",
        "    else:\n",
        "        return\n",
        "        # TODO Implement me!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "cellView": "form",
        "id": "zCobLakM1esy",
        "outputId": "a6dc49ca-afe6-4042-dd10-2f0d25940f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-bdf477a27bf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mcheck_relu_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mplot_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-bdf477a27bf1>\u001b[0m in \u001b[0;36mcheck_relu_function\u001b[0;34m(relu_function)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrelu_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Check if x == 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title Run to test your function.\n",
        "\n",
        "\n",
        "def plot_relu(relu_function):\n",
        "    max_int = 5\n",
        "    # Generete 100 evenly spaced points from -max_int to max_int\n",
        "    x = np.linspace(-max_int, max_int, 1000)\n",
        "    y = np.array([relu_function(xi) for xi in x])\n",
        "    plt.plot(x, y, label=\"ReLU\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.xticks(np.arange(min(x), max(x) + 1, 1))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def check_relu_function(relu_function):\n",
        "    # Generete 100 evenly spaced points from -100 to -1\n",
        "    x = np.linspace(-100, -1, 100)\n",
        "    y = np.array([relu_function(xi) for xi in x])\n",
        "    assert (y == 0).all()\n",
        "\n",
        "    # Check if x == 0\n",
        "    x = 0\n",
        "    y = relu_function(x)\n",
        "    assert y == 0\n",
        "\n",
        "    # Generete 100 evenly spaced points from 0 to 100\n",
        "    x = np.linspace(0, 100, 100)\n",
        "    y = np.array([relu_function(xi) for xi in x])\n",
        "    assert np.allclose(x, y)\n",
        "\n",
        "    print(\"Your ReLU function is correct!\")\n",
        "\n",
        "\n",
        "check_relu_function(relu)\n",
        "plot_relu(relu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kken6_XvDdOK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Answer to code task (Try not to peek until you've given it a good try!')\n",
        "def relu(x):\n",
        "    if x > 0:\n",
        "        return x\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "\n",
        "check_relu_function(relu)\n",
        "plot_relu(relu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mgIAyE2Fx3O"
      },
      "source": [
        "Let's try to `jit` this function to speed up compilation and then try to call it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YDkiNlRF6jn"
      },
      "outputs": [],
      "source": [
        "relu_jit = jax.jit(relu)\n",
        "\n",
        "key = jax.random.PRNGKey(42)\n",
        "# Gen 1000000 random numbers and pass them to relu\n",
        "num_random_numbers = 1000000\n",
        "x = jax.random.normal(key, (num_random_numbers,))\n",
        "\n",
        "# Should raise an error.\n",
        "try:\n",
        "    relu_jit(x)\n",
        "except Exception as e:\n",
        "    print(\"Exception {}\".format(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7q33C4pHOQW"
      },
      "source": [
        "**Why does this fail?**\n",
        "\n",
        "\n",
        "> As mentioned above, JAX transforms first converts python functions into an intermediate language called *jaxpr*. Jaxpr only captures what is executed on the parameters given to it during tracing, so this means during conditional calls, jaxpr only considers the branch taken.\n",
        "> \n",
        "> When jit-compiling a function, we want to compile and cache a version of the function that can handle multiple different argument types (so we don't have to recompile for each function evaluation). For example, when we compile a function on an array `jnp.array([1., 2., 3.], jnp.float32)`, we would likely also want to use the compiled function for `jnp.array([4., 5., 6.], jnp.float32)`. \n",
        "> \n",
        "> To achieve this, JAX traces your code based on abstract values. The default abstraction level is a ShapedArray - array that has a fixed size and dtype, for example, if we trace a function using `ShapedArray((3,), jnp.float32)`,  it can be reused for any concrete array of size 3, and float32 dtype. \n",
        "> \n",
        "> This does come with some challenges. Tracing that relies on concrete values becomes tricky and sometimes results in `ConcretizationTypeError` as in the ReLU function above. Furthermore, when tracing a function with conditional statements (\"if ...\"), JAX doesn't know which branch to take when tracing and so tracing can't occur.\n",
        "\n",
        "**TLDR**: JAX tracing doesn't work well with conditional statements (\"if ...\"). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLswU8aMEQ9K"
      },
      "source": [
        "To solve this, we have two options:\n",
        "- Use static arguments to make sure JAX traces on a concrete value level - this is not ideal if you need to retrace a lot. Example - bottom of this [section](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#python-control-flow-jit).\n",
        "- Use builtin JAX condition flow primitives such as [`lax.cond`](https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.cond.html) or [`jnp.where`](https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.where.html).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX8k4R7daBpP"
      },
      "source": [
        "**Exercise 1.3 - Code Task** : Let's convert our ReLU function above to work with jit.\n",
        "\n",
        "**Useful methods:**  [`jnp.where`](https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.where.html) (or [`jnp.maximum`](https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.maximum.html), if you prefer.) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-4mXLwqaK-b"
      },
      "outputs": [],
      "source": [
        "# Implement a jittable ReLU\n",
        "def relu(x):\n",
        "    # TODO Implement ME!\n",
        "    return ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5fq_QRoaaG5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Run to test your function.\n",
        "check_relu_function(relu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLtBaplGxlS3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Answer to code task (Try not to peek until you've given it a good try!')\n",
        "def relu(x):\n",
        "    return jnp.where(x > 0, x, 0)\n",
        "    # Another option - return jnp.maximum(x,0)\n",
        "\n",
        "\n",
        "check_relu_function(relu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYogDOCLiLXN",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Now let's see the performance benefit of using jit! (Run me)\n",
        "\n",
        "# jit our function\n",
        "relu_jit = jax.jit(relu)\n",
        "\n",
        "# generate random input\n",
        "key = jax.random.PRNGKey(42)\n",
        "num_random_numbers = 1000000\n",
        "x = jax.random.normal(key, (num_random_numbers,))\n",
        "\n",
        "# time normal jit function\n",
        "jax_time = %timeit -o -n 10 relu(x).block_until_ready()\n",
        "\n",
        "# Warm up/Compile - first run for jitted function\n",
        "relu_jit(x).block_until_ready()\n",
        "\n",
        "# time jitted function\n",
        "jax_jit_time = %timeit -o -n 10 relu_jit(x).block_until_ready()\n",
        "\n",
        "# Let's plot the performance difference\n",
        "jax_avg_time = np.mean(jax_time.all_runs)\n",
        "jax_jit_avg_time = np.mean(jax_jit_time.all_runs)\n",
        "data = {\"JAX (no jit)\": jax_avg_time, \"JAX (with jit)\": jax_jit_avg_time}\n",
        "\n",
        "plot_performance(data, title=\"Average time taken for ReLU function\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxq-z-xzs40s"
      },
      "source": [
        "## Automatic gradient computation\n",
        "\n",
        "The `grad` transformation is used to automatically compute the gradient of a function in JAX. It can be applied to Python and NumPy functions, which means you can differentiate through loops, branches, recursion, and closures.  \n",
        "\n",
        "`grad` takes in a function `f` and returns a function. If `f` is a mathematical function $f(x)$, then `grad(f(x))` corresponds to $f'(x)=\\frac{df}{dx}$. Then `grad(f)(x_0)` yields $f'(x_0)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C49R8EOs-GHe"
      },
      "source": [
        "Let's take a simple function $f(x)=6x^4-9x+4$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUMepl6J-dQP"
      },
      "outputs": [],
      "source": [
        "f = lambda x: 6 * x**4 - 9 * x + 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ayvrkpiBiu4"
      },
      "source": [
        "We can compute the gradient of this function - $f'(x)$ and evaluate it at $x=3$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNm9hS2S-vJk"
      },
      "outputs": [],
      "source": [
        "dfdx = grad(f)\n",
        "dfdx_3 = dfdx(3.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcRUywsnF3LZ"
      },
      "source": [
        "**Exercise 1.4 - Math Task**: Can you calculate $f'(2)$ by hand?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PybYK6NEFWrD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "answer = 0  # @param {type:\"integer\"}\n",
        "\n",
        "dfdx_2 = dfdx(2.0)\n",
        "\n",
        "assert (\n",
        "    answer == dfdx_2\n",
        "), \"Incorrect answer, hint https://en.wikipedia.org/wiki/Power_rule#Statement_of_the_power_rule\"\n",
        "\n",
        "print(\"Nice, you got the correct answer!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Answer to math task (Try not to run until you've given it a good try!') \n",
        "%%latex                                                  \n",
        "\\begin{aligned}\n",
        "f(x) & = 6x^4-9x+4 \\\\\n",
        "f'(x) & = 24x^3 -9  && \\triangleright \\textrm{Power Rule.}  \\\\ \n",
        "f'(2) &  = 24(2)^3 -9 = 183 && \\triangleright \\textrm{Substituting x=2} \\\\\n",
        "\\end{aligned}"
      ],
      "metadata": {
        "id": "CAwlhxIlRPp9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcB5ZjojH67Q"
      },
      "source": [
        "We can also chain `grad` to calculate higher order deratives. \n",
        "\n",
        "We can calculate $f'''(x)$ as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "013SFq7BE54W"
      },
      "outputs": [],
      "source": [
        "d3dx = grad(grad(grad(f)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_r9VQGoIsa6"
      },
      "source": [
        "**Exercise 1.5 - Math Task**: How about $f'''(2)$ by hand?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WZUArv4TInPg"
      },
      "outputs": [],
      "source": [
        "answer = 0  # @param {type:\"integer\"}\n",
        "\n",
        "d3dx_2 = d3dx(2.0)\n",
        "\n",
        "assert answer == d3dx_2, \"Incorrect answer, hint ...\"\n",
        "\n",
        "print(\"Nice, you got the correct answer!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Answer to math task (Try not to run until you've given it a good try!') \n",
        "%%latex \n",
        "\n",
        "\\begin{aligned}\n",
        "f(x) & = 6x^4-9x+4 \\\\\n",
        "f'(x) & = 24x^3 -9  && \\triangleright \\textrm{Power Rule.}  \\\\\n",
        "f''(x) & = 72x^2  && \\triangleright \\textrm{Power Rule.}  \\\\\n",
        "f'''(x) & = 144x && \\triangleright \\textrm{Power Rule.} \\\\\n",
        "f'''(2) & = 144(2)=288 && \\triangleright \\textrm{Substituting x=2} \\\\ \n",
        "\\end{aligned}"
      ],
      "metadata": {
        "id": "TCC7SkH8MMVk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3QgJNU9XYyz"
      },
      "source": [
        "Another useful method is `value_and_grad`, where we can get the value ($f(x)$) and gradient ($f'(x)$). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3zeSv6gXuyd"
      },
      "outputs": [],
      "source": [
        "from jax import value_and_grad\n",
        "\n",
        "f_x, dy_dx = value_and_grad(f)(2.0)\n",
        "print(f\"f(x): {f_x} fâ²(x): {dy_dx} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> For partial derivatives, you need to use the [`argnums`](https://jax.readthedocs.io/en/latest/_autosummary/jax.grad.html) param to specify which variables you want to differentiate with respect to. \n",
        "\n"
      ],
      "metadata": {
        "id": "_vUr-B6gSxnu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MktOLPnwvnH3"
      },
      "source": [
        "**Exercise 1.6 - Group Task:** Chat with neighbour/think about how JAX's automatic differentiation compares to other libraries such as Pytorch or Tensorflow. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another useful application related to `grad` is when you want your `grad` function to return auxiliary (extra) data, that you don't want differentiated. You can use the `has_aux` parameter to do this (example in \"Auxiliary data\" section in [here](https://github.com/google/jax/blob/main/docs/jax-101/01-jax-basics.ipynb))."
      ],
      "metadata": {
        "id": "rvXlE7z02M2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pure Functions\n",
        "\n",
        "JAX transformation and compilation are designed to work reliably on **pure functions** (see [Wikipedia page on pure functions](https://en.wikipedia.org/wiki/Pure_function)). These functions have the following properties:\n",
        "1. All **input** data is passed through the **function's parameters**. \n",
        "2. All **results** are output through the **function's return**. \n",
        "3. The function always returns the same **result** if invoked with the **same inputs**. What if your function involves randomness? Pass in the random seed!\n",
        "4. **No [side-effects](https://en.wikipedia.org/wiki/Side_effect_(computer_science))** - no mutation of non-local variables or input/output streams.  \n",
        " \n",
        "\n",
        "Let's see what could happen if we don't stick to using pure functions."
      ],
      "metadata": {
        "id": "fT56qxXzTVKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Side Effects"
      ],
      "metadata": {
        "id": "Mad7l7s0CtT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's call print within a function."
      ],
      "metadata": {
        "id": "xkQWTE2Xe955"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def impure_print_side_effect(x):\n",
        "    print(\"Print me!\")  # This is a side-effect\n",
        "    return x\n",
        "\n",
        "\n",
        "# The side-effects appear during the first run\n",
        "print(\"First call: \", jax.jit(impure_print_side_effect)(4.0))"
      ],
      "metadata": {
        "id": "S9aeUdUoBmCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, the print statement is called.\n",
        "\n",
        "Let's call this function again. "
      ],
      "metadata": {
        "id": "nu4rnyS7ox_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsequent runs with parameters of same type and shape may not show the side-effect\n",
        "# This is because JAX now invokes a cached compilation of the function\n",
        "print(\"Second call: \", jax.jit(impure_print_side_effect)(5.0))"
      ],
      "metadata": {
        "id": "-wnkIqAxfDeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ah, no print statement! Since JAX cached the compilation of the function, `print()` calls will only happen during tracing and not every time the function is called. "
      ],
      "metadata": {
        "id": "64rNvVnwo-eB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JAX re-runs the Python function when the type or shape of the argument changes\n",
        "print(\n",
        "    \"Third call, different type: \", jax.jit(impure_print_side_effect)(jnp.array([5.0]))\n",
        ")"
      ],
      "metadata": {
        "id": "Mp_CkOL-o86t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, we called the function with a different shaped object and so it triggered the re-tracing of the function and print was called again. "
      ],
      "metadata": {
        "id": "XFogrIf5fbLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To print values in compiled functions, use [host callbacks](https://jax.readthedocs.io/en/latest/jax.experimental.host_callback.html?highlight=print#jax.experimental.host_callback.id_print)([example](https://github.com/google/jax/issues/196#issuecomment-1191155679)) or if your jax version>=0.3.16, you can use [`jax.debug.print`](https://jax.readthedocs.io/en/latest/debugging/print_breakpoint.html). \n"
      ],
      "metadata": {
        "id": "pqV6_25GCxHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Global variables"
      ],
      "metadata": {
        "id": "EqL1-TGaC8Ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using global variables can also lead to some undesired consequences!"
      ],
      "metadata": {
        "id": "t8dzJog8tMe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = 0.0\n",
        "\n",
        "\n",
        "def impure_uses_globals(x):\n",
        "    return x + g\n",
        "\n",
        "\n",
        "# JAX captures the value of the global during the first run\n",
        "print(\"First call: \", jax.jit(impure_uses_globals)(4.0))"
      ],
      "metadata": {
        "id": "vwAkKrDiCXO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This prints 4, using the original value of `g`.\n",
        "\n",
        "Let's update `g` and call our function again."
      ],
      "metadata": {
        "id": "pWNE8B5btcfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = 10.0  # Update the global\n",
        "\n",
        "# Subsequent runs may silently use the cached value of the globals\n",
        "print(\"Second call: \", jax.jit(impure_uses_globals)(4.0))"
      ],
      "metadata": {
        "id": "mLMpdQZwtUEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though we updated our global variable, this still prints 4, using the original value of `g`. This is because the value of `g` was cached."
      ],
      "metadata": {
        "id": "o3-ygEx0tpBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JAX re-runs the Python function when the type or shape of the argument changes\n",
        "# This will end up reading the latest value of the global\n",
        "print(\"Third call, different type: \", jax.jit(impure_uses_globals)(jnp.array([4.0])))"
      ],
      "metadata": {
        "id": "LDecWNyktWDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the side-effects example, re-tracing gets triggered when the shape of our input has changed. In this case, our function now uses the updated value of `g`."
      ],
      "metadata": {
        "id": "3mIZaXOqt5ix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the global variables are cached, it is still okay to use global **constants** inside jax functions."
      ],
      "metadata": {
        "id": "aLis2BV04BQK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCUB9YkCnCFb"
      },
      "source": [
        "## Function vectorization with vmap\n",
        "\n",
        "vmap (Vectorizing map) automatically vectorizes your python functions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e858lqfYKd4d"
      },
      "source": [
        "Let's define a simple function that calculates the min and max of an input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6qalyXgDsKB"
      },
      "outputs": [],
      "source": [
        "def min_max(x):\n",
        "    return jnp.array([jnp.min(x), jnp.max(x)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muSIsUkgKlxh"
      },
      "source": [
        "We can apply this function to the vector - `[0, 1, 2, 3, 4]` and get the min and max values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5wIeGieKsWG"
      },
      "outputs": [],
      "source": [
        "x = jnp.arange(5)\n",
        "min_max(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PkC7NnPLNXq"
      },
      "source": [
        "What about if we want to apply this to a batch/list of vectors (i.e. calculate the min and max independently across multiple batches)? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRngFfwCMHLd"
      },
      "source": [
        "Let's create our batch - 3 vectors of size 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKuh459OD6jx"
      },
      "outputs": [],
      "source": [
        "batch_size = 3\n",
        "batched_x = np.arange(15).reshape((batch_size, -1))\n",
        "print(batched_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hApYpVEvNS1y"
      },
      "source": [
        "**Exercise 1.7 - Question**: What do you think would be the result if we passed batch_x into `min_max`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu6C3J0kMrtj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "batch_min_max_output = [[0,4],[5,9],[10,14]]  # @param [\"[[0,4],[5,9],[10,14]]\", \"[[0,10],[1,11],[2,12],[3,13],[4,14]]\", \"[0,14]\"] {type:\"raw\"}\n",
        "\n",
        "assert (batch_min_max_output == np.array(min_max(batched_x))).all(), \"Incorrect answer.\"\n",
        "\n",
        "print(\"Nice, you got the correct answer!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K0weiHOOb8L"
      },
      "source": [
        "So the above is not what we want. The `min` and `max` is applied across the entire batch, when we want the min and max per vector/mini-batch. \n",
        "\n",
        "We can also manually batch this by `jnp.stack` and a for loop, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8RdAqr8N-Fd"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def manual_batch_min_max_loop(batched_x):\n",
        "    min_max_result_list = []\n",
        "    for x in batched_x:\n",
        "        min_max_result_list.append(min_max(x))\n",
        "    return jnp.stack(min_max_result_list)\n",
        "\n",
        "\n",
        "print(manual_batch_min_max_loop(batched_x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmu3VVtMR0GV"
      },
      "source": [
        "Or, just manually updating the `axis` in `jnp.min` and `jnp.max`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzxmORv-RcUg"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def manual_batch_min_max_axis(batched_x):\n",
        "    return jnp.array([jnp.min(batched_x, axis=1), jnp.max(batched_x, axis=1)]).T\n",
        "\n",
        "\n",
        "print(manual_batch_min_max_axis(batched_x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CetKYASUSE4Q"
      },
      "source": [
        "These approaches both work, but we need to change our function to work with batches. We can't just run the same code across a batch of data.\n",
        "\n",
        "There is where `vmap` becomes useful! Using `vmap` we can write a function once, as if it is working on a single element, and then use `vmap` to automatically vectorize it! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2F8WUNQROkQ"
      },
      "outputs": [],
      "source": [
        "# define our vmap function using our original single vector function\n",
        "@jit\n",
        "def min_max_vmap(batched_x):\n",
        "    return vmap(min_max)(batched_x)\n",
        "\n",
        "\n",
        "# Run it on a single vecor\n",
        "## We add extra dimention in a single vector, shape changes from (5,) to (1,5), which makes the vmapping possible\n",
        "x_with_leading_dim = jax.numpy.expand_dims(x, axis=0)\n",
        "print(f\"Single vector: {min_max_vmap(x_with_leading_dim)}\")\n",
        "\n",
        "# Run it on batch of vectors\n",
        "print(f\"Batch/list of vector:{min_max_vmap(batched_x)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3bome92VRL6"
      },
      "source": [
        "So this is really convenient, but what about performance? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1Nb4uniUUor"
      },
      "outputs": [],
      "source": [
        "batched_x = np.arange(50000).reshape((500, 100))\n",
        "\n",
        "# Trace the functions with first call\n",
        "manual_batch_min_max_loop(batched_x).block_until_ready()\n",
        "manual_batch_min_max_axis(batched_x).block_until_ready()\n",
        "min_max_vmap(batched_x).block_until_ready()\n",
        "\n",
        "min_max_forloop_time = %timeit -o -n 10 manual_batch_min_max_loop(batched_x).block_until_ready()\n",
        "min_max_axis_time = %timeit -o -n 10 manual_batch_min_max_axis(batched_x).block_until_ready()\n",
        "min_max_vmap_time = %timeit -o -n 10 min_max_vmap(batched_x).block_until_ready()\n",
        "\n",
        "print(\n",
        "    f\"Avg Times (lower is better) - Naive Implementation: {np.round(np.mean(min_max_forloop_time.all_runs),5)} Manually Vectorized: {np.round(np.mean(min_max_axis_time.all_runs),5)} Vmapped Function: {np.round(np.mean(min_max_vmap_time.all_runs),5)} \"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYL758zCYsrR"
      },
      "source": [
        "So `vmap` should be similar in performance to manually vectorized code (if everything is implemented well), and much better than naively vectorized code (i.e. for loops). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAO9dOdrtiqI"
      },
      "source": [
        "## Paralelization with pmap\n",
        "\n",
        "ð¡**For this subsection, please ensure that colab is using a `TPU` runtime. If no `TPU` runtimes are available, select `Harware Accelerator` - `None` for a cpu runtime.** \n",
        "\n",
        "With `pmap` we can convert a function written for a single device to a function that can run in parallel across many devices. \n",
        "\n",
        "**Difference between `vmap` and `pmap`**:\n",
        "\n",
        "So both `pmap` and `vmap` transform a function to work over an array, but they differ in implementation. `vmap` adds an extra batch dimension to all the operations in a function, while `pmap` replicates the function and executes each replica on its own XLA device in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gUYA277soR-0"
      },
      "outputs": [],
      "source": [
        "# @title Check the device you are using (Run Cell)\n",
        "print(f\"Num devices: {jax.device_count()}\")\n",
        "print(f\" Devices: {jax.devices()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qhlBnLs6AYL"
      },
      "source": [
        "Let's try and `pmap` a batch of dot products.\n",
        "\n",
        "Here is an illustration of how we would typically do this sequentially: \n",
        "\n",
        "[Source](https://www.assemblyai.com/blog/why-you-should-or-shouldnt-be-using-jax-in-2022/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fz1i2AwA5_7J"
      },
      "outputs": [],
      "source": [
        "# @title Illustration of Sequential Dot Product (Run me)\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\n",
        "    '<iframe width=\"560\" height=\"315\" src=\"https://www.assemblyai.com/blog/content/media/2022/02/not_parallel-2.mp4\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTmWNFZ08f8n"
      },
      "source": [
        "Here is the code implementation of this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqTuMldJ9Uv5"
      },
      "outputs": [],
      "source": [
        "# Let's generate a batch of size 8, each with a matrix of size (500, 600)\n",
        "\n",
        "# Let create 8 keys, 1 for each batch\n",
        "keys = jax.random.split(jax.random.PRNGKey(0), 8)\n",
        "\n",
        "# Let create our batches\n",
        "mats = jnp.stack([jax.random.normal(key, (500, 600)) for key in keys])\n",
        "\n",
        "\n",
        "def dot_product_sequential():\n",
        "    @jit\n",
        "    def avg_dot_prod(mats):\n",
        "        result = []\n",
        "        # Loop through batch and compute dp\n",
        "        for mat in mats:\n",
        "            # dot product between the a mat and mat.T (transposed version)\n",
        "            result.append(jnp.dot(mat, mat.T))\n",
        "        return jnp.stack(result)\n",
        "\n",
        "    avg_dot_prod(mats).block_until_ready()\n",
        "\n",
        "\n",
        "run_sequential = %timeit -o -n 5 dot_product_sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBEtecJX-0AW"
      },
      "source": [
        "Here is an illustration of how we would do this in parallel \n",
        "\n",
        "[Source](https://www.assemblyai.com/blog/why-you-should-or-shouldnt-be-using-jax-in-2022/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uswxurmn-5oC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Illustration of Parallel Dot Product (Run me)\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\n",
        "    '<iframe width=\"560\" height=\"315\" src=\"https://www.assemblyai.com/blog/content/media/2022/02/parallelized.mp4\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGsq8iTA_N9U"
      },
      "source": [
        "Here is code implementation of batched dot products:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ygFWDfQIoeC"
      },
      "source": [
        "First, we will create `8` random matrices (one for each available tpu devices - colab tpu's have 8 available [devices](https://cloud.google.com/tpu/docs/system-architecture-tpu-vm) or the 8 cpu cores as we configured)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZLMx06_K_qR"
      },
      "outputs": [],
      "source": [
        "# Let create 8 keys, 1 for each batch\n",
        "keys = jax.random.split(jax.random.PRNGKey(0), 8)\n",
        "\n",
        "# Each replicated pmapped function get a different key\n",
        "mats = pmap(lambda key: jax.random.normal(key, (500, 600)))(keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BkMsaOtLISj"
      },
      "source": [
        "The leading dimension here needs to equal the dimension of available devices (since we are sending a batch to each device)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWrdv_2wLG4T"
      },
      "outputs": [],
      "source": [
        "print(mats.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnqblcUsLaKZ"
      },
      "source": [
        "Using `pmap` to generate the batches ensures these batches are of type `ShardedDeviceArray`. This is similar to an ndarray, except each batch/shared is stored in the memory of multiple devices, so they can be used in subsequent `pmap` operations without moving data around between devices (GPU/TPU) and hosts (cpu). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAeaBCvcLQWg"
      },
      "outputs": [],
      "source": [
        "print(type(mats))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVz0gOWG9pkr"
      },
      "outputs": [],
      "source": [
        "def dot_product_parallel():\n",
        "\n",
        "    # Run a local matmul on each device in parallel (no data transfer)\n",
        "    result = pmap(lambda x: jnp.dot(x, x.T))(\n",
        "        mats\n",
        "    ).block_until_ready()  # result.shape is (8, 5000, 5000)\n",
        "\n",
        "\n",
        "run_parallel = %timeit -o -n  5 dot_product_parallel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64gfyF3ENQzU"
      },
      "source": [
        "It is simple as that. Our dot product now runs in parallel across available devices (cpu, gpus or tpus). As we have more cores/devices, this code will automatically scale! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qcQXSbANP_M",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Let's plot the performance difference (Run Cell)\n",
        "\n",
        "jax_parallel_time = np.mean(run_parallel.all_runs)\n",
        "jax_seq_time = np.mean(run_sequential.all_runs)\n",
        "\n",
        "\n",
        "data = {\"JAX (seq)\": jax_seq_time, \"JAX (parallel - pmap)\": jax_parallel_time}\n",
        "\n",
        "plot_performance(data, title=\"Average time taken for Seq vs Parallel Dot Product\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0j8iJRFUz6v"
      },
      "source": [
        "For some problems, the speed can be directly proportional to the number of devices -- $Nx$ speed up for $N$ devices! \n",
        "\n",
        "We showed an example of using `pmap` for *pure* parallelism, where there is no communication between devices. JAX also has various operations for communication across distributed devices ( more on this [here](https://jax.readthedocs.io/en/latest/jax-101/06-parallelism.html#communication-between-devices).)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAtms17jtCOU"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# PART 2 - Optimization using Optax\n",
        "\n",
        "<hr>\n",
        "\n",
        "[Optax](https://github.com/deepmind/optax), leverages from the capabilities of JAX, in particular automatic differentiation, to run optimization methods such as vanilla gradient descent, or more advanced ones such as ADAM, on any loss function we may have. \n",
        "\n",
        "Below we show how to use Optax to train a simple linear model of the form \n",
        "\n",
        "$$y=w\\tr x + b,\\,w \\in \\reals^m,\\;y,b \\in \\reals.$$\n",
        "\n",
        "Below is a little function to simulate noisy samples drawn from a linear model, and a classic mean squared loss function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import random\n",
        "\n",
        "def sim_linear_model(w, b, num_samples, noise_std=0.05):\n",
        "  \"\"\"\n",
        "  given a linear coefficientw vector w, a bias b and a non-negative integer n\n",
        "  generate n samples according to y = wx + b + v\n",
        "  where v is a random Gaussian variable with mean 0\n",
        "  and standard deviation 0.1\n",
        "  \"\"\"\n",
        "  sample_dim = len(w)\n",
        "  X = random.uniform(size=(sample_dim,num_samples))\n",
        "  noise = noise_std*random.normal(size=num_samples)\n",
        "  y = w @ X + b + noise\n",
        "  return X,y\n",
        "\n",
        "\n",
        "def loss(X, y, w, b):\n",
        "  \"\"\"\n",
        "  JAX-based implementation of mean squared loss\n",
        "  \"\"\"\n",
        "  errors = jnp.square(y - w.T @ X - b)\n",
        "  return jnp.mean(errors)\n",
        "\n",
        "#\n",
        "# ground truth\n",
        "#\n",
        "w = [0.4]\n",
        "b = -0.2\n",
        "#\n",
        "# draw samples\n",
        "#\n",
        "X,y = sim_linear_model(w, b, 100)\n"
      ],
      "metadata": {
        "id": "AKuLize6bkzY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optax workflow\n",
        "\n",
        "Since JAX is pure function-based, Optax functions need to be pure functions too. Thus, in order to update the model's parameters, two functions are called in sequence:\n",
        "\n",
        "1. `optimizer.update(theta,state)` if the model parameters are $\\theta$, this function returns the update that needs to be applied to theta in order to obtain a new iterate: $\\Delta \\theta$. The `state` stores past information gathered by the optimizer which might influence the computation of $\\Delta \\theta$.\n",
        "1. `optax.apply(theta,delta_theta)` simply adds `delta_theta` to `theta`\n",
        "\n",
        "One important aspect of Optax is that it expects the model parameters to be provided as name-value pairs in a dictionary. In the linear model below we have two parameters $w$ and $b$ so that $\\theta=(w,b)$ and $\\Delta\\theta=(\\Delta w,\\Delta b)$.\n"
      ],
      "metadata": {
        "id": "cY6EQK582Phk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install -U optax\n",
        "\n",
        "import optax\n",
        "import jax.numpy.linalg as jla\n",
        "\n",
        "# \n",
        "# JAX autograd:  the returned value gloss is a function \n",
        "# that computes the gradient of loss(X,y,w,b) with respect to w and b (args 2 and 3)\n",
        "# \n",
        "gloss = jax.grad(loss, argnums=(2,3))\n",
        "\n",
        "\n",
        "def train_model_optax(X, y, fun, grad, stepsize=1e-2,tolerance=1e-4,maxiter=1000):\n",
        "  \"\"\"\n",
        "  optimization using Optax\n",
        "  :param X: reference inputs\n",
        "  :param y: reference output\n",
        "  :param fun: cost function \n",
        "  :param grad: gradient of the cost function\n",
        "  \"\"\"\n",
        "  #\n",
        "  # create optimizer\n",
        "  # this guy defines how to update the parameters in each iteration\n",
        "  #\n",
        "  optimizer = optax.sgd(stepsize) # TRY other optimizers and stepsizes!! optax.adam\n",
        "  #\n",
        "  # initial parameters\n",
        "  #\n",
        "  # Optax expects a dictionary parameters\n",
        "  # in this case we have only one: w\n",
        "  #\n",
        "  theta_t = {\"w\": jnp.zeros(X.shape[0]), \"b\":jnp.ones(1)}\n",
        "  #\n",
        "  # all Optax optimizers have an inner state that needs to \n",
        "  # be stored and updated between calls\n",
        "  #\n",
        "  state_t = optimizer.init(theta_t)\n",
        "  \n",
        "  params     = list()\n",
        "  costs      = list()\n",
        "  grad_norms = list()\n",
        "  #\n",
        "  # main optimization loop\n",
        "  #\n",
        "  for t in range(maxiter):\n",
        "    #\n",
        "    # values at current iteration\n",
        "    #\n",
        "    w_t = theta_t[\"w\"]\n",
        "    b_t = theta_t[\"b\"]\n",
        "    g_t = grad(X,y,w_t,b_t)\n",
        "    f_t = fun(X,y,w_t,b_t)\n",
        "    n_t = jla.norm(g_t)\n",
        "    #\n",
        "    # check for stopping condition\n",
        "    #\n",
        "    if n_t < tolerance:\n",
        "      break\n",
        "    #\n",
        "    # store current solution\n",
        "    #\n",
        "    params.append(theta_t)\n",
        "    costs.append(f_t)\n",
        "    grad_norms.append(n_t)\n",
        "    #\n",
        "    # update solution (here comes Optax)\n",
        "    #\n",
        "    # Optax expects a dictionary of gradients, one per parameter\n",
        "    # corresponding to the dictionary of parameters above\n",
        "    #\n",
        "    g_t = {\"w\":g_t[0],\"b\":g_t[1]} \n",
        "    d_t, state_t = optimizer.update(g_t, state_t)\n",
        "    theta_t = optax.apply_updates(theta_t, d_t)\n",
        "\n",
        "  return params,costs,grad_norms\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "a1u1ZpbAqRTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running our optax-powered optimizer\n",
        "\n",
        "Run the cell below to see our latest method in action.\n",
        "\n",
        "<hr>\n",
        "\n",
        "**ExcerciseL** try again, now changing the optimizer and/or the stepsize (see [Common Optimizers](https://optax.readthedocs.io/en/latest/api.html) ). One popular one is ADAM (`optax.adam`)\n"
      ],
      "metadata": {
        "id": "j4Sxc76A49jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_trajectory(params,costs,norms):\n",
        "  \"\"\"\n",
        "  helper function for plotting our thing\n",
        "  \"\"\"\n",
        "  niter = len(costs)\n",
        "\n",
        "  plt.figure(figsize=(15,5))\n",
        "\n",
        "  plt.subplot(1,3,1)\n",
        "  plt.semilogy(costs)\n",
        "  plt.xlabel('iteration')\n",
        "  plt.ylabel('loss')\n",
        "  plt.title('evolution of loss across iterations')\n",
        "  plt.grid(True)\n",
        "\n",
        "#\n",
        "# call the algorithm\n",
        "#\n",
        "params,costs,norms = train_model_optax(X, y, loss, gloss,stepsize=0.1)\n",
        "\n",
        "plot_trajectory(params,costs,norms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "YBN1Ov1dta8Z",
        "outputId": "01a68be8-ab12-4165-e667-6a9425a602cc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-506f68364703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# call the algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcosts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model_optax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstepsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mplot_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcosts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_model_optax' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exuVety_bFhQ"
      },
      "source": [
        "# Training Models with Haiku\n",
        "\n",
        "So far we've seen how to use JAX and Optax to implement an optimization loop.\n",
        "Thanks to these two libraries, we can exploit our computing resources to the maximum, forget about computing gradients by hand, and to define the descent direction altogether.\n",
        "\n",
        "What if we now want to build a deep neural model? If we want to do it with JAX, we need JAX-enabled blocks (dense, convolutional, relus, maxpool, etc.) and a way to construct and maintain the state of the resulting mammoth.\n",
        "\n",
        "Here's where [Haiku](https://github.com/deepmind/dm-haiku) comes in, by providing a JAX-based alternative to those familiar with  the traditional Pytorch or Tensorflow libraries.\n",
        "\n",
        "## Haiku is object oriented\n",
        "\n",
        "Haiku is an *object-oriented* library, meaning that our models, their parameters, etc., are represented as _instances_ of _object classes_. If you are not familiar with object oriented programming, you should learn this concept first. There are many tutorials on the subject ([example](https://realpython.com/python3-object-oriented-programming/)).\n",
        "\n",
        "## JAX is functional oriented\n",
        "\n",
        "However, there is a twist, as JAX follows the  _functional programming_ paradigm! \n",
        "\n",
        "Haiku modules are similar to standard python objects (they have references to their own parameters and functions). However, since JAX operates on *pure functions*, Haiku modules **cannot be directly instantiated**, but rather they need to be **wrapped into pure function transformations.**\n",
        "\n",
        "So, the overall rationale is to:\n",
        "\n",
        "* write an object for your model\n",
        "* wrap the object so that it is seen by JAX as a set of pure functions\n",
        "\n",
        "Don't worry. It sounds more complicated than it is."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#@title Run this cell to install Haiku!\n",
        "!pip install -U dm-haiku\n"
      ],
      "metadata": {
        "id": "lMubruAF4ZDc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wvTzTi-YJTp"
      },
      "source": [
        "## Wrapping a model in Haiku\n",
        "\n",
        "We'll now create a linear model in the way of Haiku. This linear model contains another parameter `b`, a constant (bias) term that is added to the linear combination, so that $y=wx+b$.\n",
        "\n",
        "The core object in Haiku is a `Module`. A module contains parameters and a function `__call__` that combines these parameters and user input to produce an output. This is what we could call a `block` within a Neural Network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "H_-3r49B-Orc"
      },
      "outputs": [],
      "source": [
        "import haiku as hk\n",
        "\n",
        "class MyLinearModel(hk.Module): # notice: model inherits from haiku.Module\n",
        "  \"\"\"\n",
        "  Haiku-based linear model of the form y=w*x+b\n",
        "\n",
        "  A Haiku module is expected to implement __call__ in order to produce\n",
        "  its output.\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, output_dim, name=None):\n",
        "    \"\"\"\n",
        "    :param output_dim: dimension of the model output (y)\n",
        "    \"\"\"\n",
        "    super().__init__(name=name)\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    \"\"\"\n",
        "    special function, gets called when we use the () operator on an instance\n",
        "    \"\"\"\n",
        "    j, k = x.shape[-1], self.output_dim\n",
        "    #\n",
        "    # note: the three lines below are actually called *once* and serve\n",
        "    # to declare and initialize the parameters of the model.\n",
        "    # \n",
        "    w_init = hk.initializers.TruncatedNormal(1.0 / np.sqrt(j))\n",
        "    w = hk.get_parameter(\"w\", shape=[j, k], dtype=x.dtype, init=w_init)\n",
        "    b = hk.get_parameter(\"b\", shape=[k], dtype=x.dtype, init=jnp.ones)\n",
        "    #\n",
        "    # this is the actual code that's executed when the module is called\n",
        "    #\n",
        "    return jnp.dot(x, w) + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XGOeJCH-10P"
      },
      "source": [
        "### Wrapping the Module\n",
        "\n",
        "In order for a module to be used by JAX, it needs to be treated not as an object, but as a set of pure functions plus a _state_, which has to be explicitly fed to the functions.\n",
        "\n",
        "The wrapping is done by the Haiku `transform` function. This wrapper takes a **function** of one or more Haiku Modules (not just any class) and \"eviscerates\" the modules it to bring out the parameters. \n",
        "\n",
        "In order for Haiku to know which parameters each  module has, the parameters need to be explicitly created and initialized using `hk.get_parameter`. In the module above, this is done in the `__call__` functions. \n",
        "\n",
        "(Admittedly, this is rather counter-intuitive, as it would seem that the parameters are created and initialized each time the `__call__` function is called. Also, they are not in the `__init__` method, which is the natural place for initializing things in an object. )\n",
        "\n",
        "So, the wrapping goes in two stages:\n",
        "\n",
        "1. we wrap the model (module) into a function\n",
        "1. we transform the function to obtain two other functions:\n",
        "   * an `init` function, that serves to initialize the parameters\n",
        "   * an `apply` function, which calls the function with the parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "d1yI7j2h_Esd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02919142-9456-4552-a194-071792e87ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed(init=<function without_state.<locals>.init_fn at 0x7f91700289e0>, apply=<function without_state.<locals>.apply_fn at 0x7f9170028a70>)\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# first step: wrap the module in a function\n",
        "#\n",
        "def model_fn(x):\n",
        "  \"\"\"\n",
        "  wrapper function for our model\n",
        "  \"\"\"\n",
        "  module = MyLinearModel(output_dim=1)\n",
        "  return module(x)\n",
        "\n",
        "#\n",
        "# second step: transform the function into a pair (init,apply)\n",
        "# \n",
        "wrapped_model = hk.transform(model_fn)\n",
        "print(wrapped_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different flavours of transformation\n",
        "\n",
        "As you may know from our previous tutorial on JAX, pseudo-random numbers play a central role in JAX and, because of the pure function concept, their state needs to be passed explicitly anywhere they're used.\n",
        "\n",
        "With this in mind, the functions produced by `hk.transform` include the PRNG state explicitly as their first argument in all calls, as can be seen in the  signature of the wrapper functions returned by `hk.transform`:\n",
        "\n",
        "* `init(prng,data)`\n",
        "* `apply(prng,params,data)`\n",
        "\n",
        "If we don't want or don't need to use a PRNG, we can ask for a different set of wrapper functions which do not include the PRNG as an argument. In our case, our `init` function does use PRNG since the weights are initialized randomly through `hk.initializers.TruncatedNormal`, but  our module's output is deterministic ($y=wx+b$). Accordingly, we'd like our signatures to be:\n",
        "\n",
        "* `init(prng)`\n",
        "* `apply(params,input)`\n",
        "\n",
        "This is achieved by calling `hk.without_apply_rng` to our transformed model:"
      ],
      "metadata": {
        "id": "i0OC1iQVS71H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# transform again to obtain another pair \n",
        "#\n",
        "wrapped_model = hk.without_apply_rng(wrapped_model)\n",
        "#\n",
        "# inspect the output and notice how the `apply` function has changed \n",
        "# compared to the previous value\n",
        "#\n",
        "print(wrapped_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv-q5rw7S7d_",
        "outputId": "ab7c2fc6-a0d0-4c89-82d7-d5c8d3f6674b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformed(init=<function without_state.<locals>.init_fn at 0x7f91700289e0>, apply=<function without_apply_rng.<locals>.apply_fn at 0x7f91700284d0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lao8wS3tBjc3"
      },
      "source": [
        "### Test the wrapper model\n",
        "\n",
        "Let's see how the wrapped model works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nt0srU3rQlhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e0e39a-97ea-4008-a231-2c1d03b34b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 2.]\n",
            "{'my_linear_model': {'w': DeviceArray([[-0.31118914],\n",
            "             [ 0.15653236],\n",
            "             [-0.50598097]], dtype=float32), 'b': DeviceArray([1.], dtype=float32)}}\n",
            "[0.14457041]\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# input dimention we are considering\n",
        "#\n",
        "input_dim = 3\n",
        "#\n",
        "# evaluate our model somewhere\n",
        "#\n",
        "some_x= jnp.arange(input_dim, dtype=jnp.float32)\n",
        "print(some_x)\n",
        "#\n",
        "# initialize PRNG, a must in JAX\n",
        "#\n",
        "rng_key = jax.random.PRNGKey(42)\n",
        "#\n",
        "# initialization DOES use the PRNG, and (possibly) the data too\n",
        "#\n",
        "params = wrapped_model.init(rng=rng_key, x=some_x)\n",
        "print(params)\n",
        "#\n",
        "# try it out\n",
        "#\n",
        "print(wrapped_model.apply(params,some_x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IaqVuRPg3ER"
      },
      "source": [
        "# Training a model using Haiku and Optax\n",
        "\n",
        "\n",
        "Here we show a full training loop, using Haiku and Optax. For convenience, we introduce structures like `TrainingState` and functions like `init`,`update` and `loss_fn`. Please read through to get comfortable with how you can effectively train JAX models."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load packages\n",
        "%%capture\n",
        "# need to install this for plotting.\n",
        "!pip install optax\n",
        "!pip install dm-haiku\n",
        "#\n",
        "# packages\n",
        "#\n",
        "from typing import Any, MutableMapping, NamedTuple, Tuple\n",
        "import time\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import haiku as hk\n",
        "import optax\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from livelossplot import PlotLosses\n"
      ],
      "metadata": {
        "id": "LY0t6C4OKzSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15825161-7221-4012-b3d8-a04d99d59d60"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: chex>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from optax) (0.1.5)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (1.2.0)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.21)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.20+cuda11.cudnn805)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.21.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (0.8.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (3.9.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (5.10.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dm-haiku in /usr/local/lib/python3.7/dist-packages (0.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.2.0)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define and wrap our model\n",
        "\n",
        "class MyLinearModel(hk.Module): # notice: model inherits from haiku.Module\n",
        "  \"\"\"\n",
        "  Haiku-based linear model of the form y=w*x+b\n",
        "\n",
        "  A Haiku module is expected to implement __call__ in order to produce\n",
        "  its output.\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, output_dim, name=None):\n",
        "    \"\"\"\n",
        "    :param output_dim: dimension of the model output (y)\n",
        "    \"\"\"\n",
        "    super().__init__(name=name)\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    \"\"\"\n",
        "    special function, gets called when we use the () operator on an instance\n",
        "    \"\"\"\n",
        "    j, k = x.shape[-1], self.output_dim\n",
        "    #\n",
        "    # note: the three lines below are actually called *once* and serve\n",
        "    # to declare and initialize the parameters of the model.\n",
        "    # \n",
        "    w_init = hk.initializers.TruncatedNormal(1.0 / np.sqrt(j))\n",
        "    w = hk.get_parameter(\"w\", shape=[j, k], dtype=x.dtype, init=w_init)\n",
        "    b = hk.get_parameter(\"b\", shape=[k], dtype=x.dtype, init=jnp.ones)\n",
        "    #\n",
        "    # this is the actual code that's executed when the module is called\n",
        "    #\n",
        "    return jnp.dot(x, w) + b\n",
        "\n",
        "#\n",
        "# wrap the model into a function\n",
        "#\n",
        "def model_fn(x):\n",
        "  \"\"\"\n",
        "  same wrapper function for Haiku modules, repeated for clarity\n",
        "  \"\"\"\n",
        "  module = MyLinearModel(output_dim=1)\n",
        "  return module(x).ravel()\n",
        "#\n",
        "# transform using Haiku as a pair init,apply\n",
        "#\n",
        "model = hk.without_apply_rng(hk.transform(model_fn))\n"
      ],
      "metadata": {
        "id": "0epd5-xgZPcW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import random as jrand\n",
        "from jax.numpy import linalg as jla\n",
        "\n",
        "def loss_fun_haiku(params: hk.Params, X, y):\n",
        "  \"\"\"\n",
        "  our loss function\n",
        "  \"\"\"\n",
        "  y_pred = model.apply(params, X)\n",
        "  return jnp.mean((y_pred - y) ** 2)\n",
        "\n",
        "\n",
        "def train_model_haiku(X, y, model, loss_fun, stepsize=1e-3,tolerance=1e-4,maxiter=1000,seed=42):\n",
        "  \"\"\"\n",
        "  optimization using Optax\n",
        "  :param X: reference inputs\n",
        "  :param y: reference output\n",
        "  :param fun: cost function \n",
        "  :param grad: gradient of the cost function\n",
        "  \"\"\"\n",
        "  #\n",
        "  # create optimizer\n",
        "  # this guy defines how to update the parameters in each iteration\n",
        "  #\n",
        "  optimizer = optax.sgd(stepsize) # TRY other optimizers and stepsizes!! optax.adam\n",
        "  #\n",
        "  # initialization\n",
        "  #\n",
        "  rng = jrand.PRNGKey(seed)\n",
        "  rng, init_rng = jrand.split(rng)\n",
        "  theta_t       = model.init(init_rng, X)\n",
        "  state_t       = optimizer.init(theta_t)\n",
        "  \n",
        "  params     = list()\n",
        "  losses     = list()\n",
        "  grad_norms = list()\n",
        "  #\n",
        "  # main optimization loop\n",
        "  #\n",
        "  for t in range(maxiter):\n",
        "    #\n",
        "    # values at current iteration\n",
        "    #\n",
        "    loss_t, gtheta_t  = jax.value_and_grad(loss_fun)(theta_t, X, y)\n",
        "    n_t = jnp.sqrt(jnp.sum(jnp.square(gtheta_t[\"my_linear_model\"][\"w\"])) + jnp.sum(jnp.square(gtheta_t[\"my_linear_model\"][\"b\"])))\n",
        "    #\n",
        "    # check for stopping condition\n",
        "    #\n",
        "    if t > 0 and t % 100: \n",
        "      print(n_t)\n",
        "      \n",
        "    if n_t < tolerance:\n",
        "      break\n",
        "    #\n",
        "    # store current solution\n",
        "    #\n",
        "    params.append(theta_t)\n",
        "    losses.append(loss_t)\n",
        "    grad_norms.append(n_t)\n",
        "    #\n",
        "    # update solution (here comes Optax)\n",
        "    #\n",
        "    dtheta_t, state_t = optimizer.update(gtheta_t, state_t)\n",
        "    theta_t           = optax.apply_updates(theta_t, dtheta_t)\n",
        "\n",
        "  return params,losses,grad_norms\n",
        "\n",
        "\n",
        "params,losses,norms = train_model_haiku(X, y, model, loss_fun_haiku, stepsize=1e-2)\n",
        "\n",
        "plot_trajectory(params,losses,norms)\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "29k-YKgkaspy",
        "outputId": "f098e01b-d963-46e7-e7f8-5a8259c04573"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/haiku/_src/base.py:515: UserWarning: Explicitly requested dtype float64 requested in ones is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  param = init(shape, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7446582\n",
            "1.2518684\n",
            "0.4185076\n",
            "0.13991159\n",
            "0.046771415\n",
            "0.015638953\n",
            "0.005227764\n",
            "0.0017470513\n",
            "0.0005840734\n",
            "0.00019476278\n",
            "6.411139e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAFNCAYAAACDsuPRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3gc9X3v8fd3Vxfb0kq2JNvrG9gytmQgXA1YuZUknJQ0JNA2hRAKudMkTdL0JE0gJ03TND3lHPqkaQtNS1NKEwgkB9qUEk7ISYNLLmCwzR3bYHzBBst3WxdfdPueP2ZkFkWXlbS7M7P6vJ5Hj7QzszPfWa0+mvntb35j7o6ISJKloi5ARGSyFGQikngKMhFJPAWZiCSegkxEEk9BJiKJpyCLATNbbGZuZhUTfP5VZvbjQteVx3bfYGYvmFmXmV02zPxtZnZRqeuKu/D1ao5w+28ys01Rbb8YTP3Iomdmi4GtQKW79xVq2WIzs/8E7nX3vx5h/jbgI+7+k5IWliBmdhuw092/VMRtOLDM3TcXaxtR0xGZTMbJwLNRF1FIZpaOuobxmOhRfNlxd32N4wuYD9wD7CU4Mvp0zvSjQEPOsmcD+4BKgn8aXwK2A3uAbwP14XKLAQcqwsfbgIty1vMV4Pbw55fCZbvCrzbgA8DPc5Z/PfAYcDj8/vqceauBPwN+AXQCPwaaRtnfjwKbgQPAvcD8cPqLwEC4z11A9TDPPbEfQDXwDeCV8Osbg88BmoD7gEPhdn4GpMJ5XwBeDmvdBLxthDrfCTwOdAA7gK8Mmf9G4JfhNnYAHwin3wZ8E7gf6AYuAlaEr9MhgqB+d856fgN4LqznZeBzY+3DMLU6cApwLdAL9ISv4X+M9h7LeS/cDdwe7utHgPOBh8Nt7wJuAqrC5R8Kt9cdbuMK4EKCo8DBdY62v7cBNwM/DPd5DbA0nGfAXxG8nzuAp4HTI/m7jDoYkvRFEEbrgC8DVUAzsAX49XD+T4GP5ix/I/D34c8fIgiEZqAW+FfgO+G8xeQfZK9ZNpz2AcIgAxqAg8DVQAVwZfi4MZy/miCElgPTw8c3jLC/byUI4nMIguhvgYdy5r+mzmGef2I+8FXgEWAOMJsgVP4snPcXwN8TBH4l8Kbwj6SFIHTm5+z70hG2dSHwuvB3dAawG7gsnHdy+Ed4Zbj+RuCscN5tBIH/hvC5mfD39MXwd/zW8Lkt4fK7gDeFP88CzhltH0ao1YFTcrb/tXG8x75CEH6XhctOB84FVoW/78XABuAzw20v57XaGf5cOcb+3gbsJwjLCuAO4K5w3q+Htc4Mf18rgHlR/G3q1HJ8zgNmu/tX3b3H3bcA/wi8N5z/XYI/FszMwunfDeddBXzd3be4exdwPfDeIpwavBN4wd2/4+597n4nsBF4V84y/+zuz7v7UeD7wFkjrOsq4FZ3X+/ux8Oa28J2uvG6Cviqu+9x973AnxKELQR/mPOAk929191/5sFfSj9BgJ5qZpXuvs3dXxxu5e6+2t2fdvcBd38KuBP4tXD2+4CfuPud4fr3u/sTOU//d3f/hbsPhK9FLUG497j7TwmOtK7MqfVUM6tz94Puvn6MfRivsd5jAA+7+w/CfT3q7uvc/ZHw970N+IecfR/LqjH2F+Df3P1RD9pk7+DV90svQfC3EoT2BnffNYF9njQF2ficDMw3s0ODXwT/yeaG8+8h+EOfB7yZ4NTrZ+G8+QSnlYO2E/yHm0thDd3O4LYW5Dxuz/n5CMEbecx1hQG8f8i6JlrX9nAaBEeum4Efm9kWM7su3N5m4DMERyF7zOwuM5vPMMzsAjN70Mz2mtlh4GMEp3sAiwiOQkeyY0idO8JQy611cJ9/m+D0cruZ/ZeZtY22DxMw1ntsaL2Y2XIzu8/M2s2sA/ifvLrvYxlrf2GE90sYejcRnHruMbNbzKwuz+0WlIJsfHYAW919Zs5Xxt1/A8DdDxK0OV1BcBRwV85/5VcI3qSDTgL6CE6BhuoGZuQ8zub8PNZ/+aHbGdzWy2M8b8x1mVkNwWnZpNcV1vQKgLt3uvtn3b0ZeDfw383sbeG877r7G8PnOvC/Rlj/dwna8Ba5ez3BaZ6F83YAS0epLfc1fQVYZGa5fxsnXj93f8zdLyU4Rf4BwRHtqPswhqG/z1HfYyM855sER93L3L2OIPiM/Iy6v2MW7/437n4ucCpBc8Uf5bndglKQjc+jQKeZfcHMpptZ2sxON7Pzcpb5LnAN8B5ePa2E4FTnD81siZnVEvzX/J4P34XiCYLTzkozWxmua9BegiO9kfoh3Q8sN7P3mVmFmV1B8Ca7bwL7eyfwQTM7y8yqw5rXhKcvE1nXl8xstpk1EbQB3Q5gZpeY2Snh6fhhglPKATNrMbO3hts+RvDBwsAI688AB9z9mJmdT/CPZNAdwEVmdnn4mjSa2Uin02sIjjo+H77+FxKclt9lZlVhn716d+8laOAeGG0f8nhddvPa32U+77Hh9r0D6DKzVuDjY2wjr/0dq3AzOy88Eq4k+Od7jPz2ueAUZOPg7v3AJQRtBFsJGsK/BdTnLHYvsAxod/cnc6bfCnyH4FOkrQS/9E+NsKk/JjiCOEjQlnQiEN39CPDnwC/CU49VQ2rcH9b4WYLTwM8Dl7j7vgns70/CWu4haOReymvbasbja8Ba4CmCT7fWh9MgeL1+QvCp2sPA37n7gwTtYzcQvM7tBEdB14+w/k8AXzWzToKQ/H7OfrxEcDr4WYJPFJ8AzhxuJe7eQ/CH/I5wu38HXOPuG8NFrga2hadwHyNo+xttH8byTwRtbofM7Ad5vseG+hxBcHcStKd9b8j8rwD/Em7j8nHu72jqwu0dJDgd3U9wil1y6hArIomnIzIRSTwFmYgknoJMRBJPQSYiiacgE5HEK8sr55uamnzx4sV5Ldvd3U1NTU1xCyqwpNWctHpBNZfKeGpet27dPnefPezMQlywGbevc8891/P14IMP5r1sXCSt5qTV666aS2U8NQNrXReNi0i5UpCJSOIpyEQk8RRkIpJ4sf/UMhw65u8IhgNe7e53RFySiMRMJEdkZnarme0xs2eGTL/YzDaZ2eacgel+C7jb3T9KMM6TiMhrRHVqeRtwce6E8O41NxMMJ3IqcKWZnQos5NURMftLWKOIJEQkQebuDxGMC5XrfGCzB2Pa9xAM7HYpsJMgzEBteiIyjMjGIwtvYHGfu58ePn4PcLG7fyR8fDVwAcHtwG4iGIjw5yO1kZnZtQS312Lu3Lnn3nXXmANcAtDV1UVt7UhD1sdT0mpOWr2gmktlPDW/5S1vWefuK4ebF/vGfnfvBj6Yx3K3ALcArFy50i+88MIx133fU6/w0v4NfOKSsZeNk9WrV5PP/sVF0uoF1Vwqhao5TqdqLxPc7WbQQiZ2k4u83fjAJn76Um8xNyEiJRCnIHsMWBbenKOKYGz4e4u5wdZshp1dkdwrQUQKKKruF3cS3KChxcx2mtmHPbib0CeBBwjulPx9d3+2mHW0ZOvY3e0c69WHoSJJFkkbmbtfOcL0+wluZ1YSrdkMDrywu4vXLRztJjUiEmdxOrWcNDN7l5ndcvjw4byWb81mANjY3lHMskSkyMoqyNz9P9z92vr6/I6uTm6soSoFG9s7i1yZiBRTWQXZeKVTxvzaFJsUZCKJNqWDDGBRJqUjMpGEm/JBtjCTYl/XcfZ1HY+6FBGZIAVZbfAS6PRSJLmmfJAtygQvgU4vRZJrygdZXbXRVFvFxl3qgiGSVGUVZOPtRzaoJZth024dkYkkVVkF2Xj7kQ1qzdbx/O5O+geiGdJIRCanrIJsolqyGY71DrB9f3fUpYjIBCjIePVSJX1yKZJMCjJg2ZwMKdMnlyJJpSADplelWdxYo4vHRRJKQRZqyWZ0aimSUAqyUGu2ju0HjnCkpy/qUkRknMoqyCbajwyCIzJ3eH53VxEqE5FiKqsgm2g/MoAV8wY/uVQ7mUjSlFWQTcaiWTOYUZXWJ5ciCaQgC6VSxrK5GTbuUpCJJI2CLMeKbIaN7R1Edfd1EZkYBVmOlmyGg0d62dupQRZFkkRBlqPlxF2VdHopkiQKshyt2TpA11yKJI2CLEdDTRVzMtVsUBcMkUQpqyCbTIfYQbpUSSR5yirIJtMhdtCKeXW8sKeLvv6BAlYmIsVUVkFWCC1zM/T0DbBNgyyKJIaCbAh9cimSPAqyIU6ZU0s6ZWonE0kQBdkQ0yrTLGmqYYMuVRJJDAXZMILbw6kLhkhSKMiGsSKbYceBo3Qd1yCLIkmgIBtGi3r4iySKgmwYuj2cSLIoyIaxYOZ0aqsrNFqsSEKUVZAV4hIlCAZZXD63lg06IhNJhLIKskJcojSoJVvHpvZODbIokgBlFWSFtGJehsNHe9ndoUEWReJOQTaClrlBg7+G9BGJPwXZCDTIokhyKMhGUD+jknn10xRkIgmgIBtFSzbDhl06tRSJOwXZKFqyGV7c20WvBlkUiTUF2ShWZOvo7Xe27tMgiyJxpiAbxeAgizq9FIk3Bdkols6upUKDLIrEnoJsFFUVKZbOrlWQicScgmwMLdmMxu8XiTkF2RhashlePnSUjmO9UZciIiMoqyAr1OgXuVbM09hkInFXVkFWyNEvBg2OFqvTS5H4KqsgK4b59dPITNMgiyJxpiAbg5nRms2wUbeHE4ktBVkegtvDaZBFkbhSkOWhJVtH57E+Xjl8LOpSRGQYCrI8rAgvVdqoS5VEYklBloflg0GmTy5FYklBloe6aZUsmDldfclEYkpBlqfWbIaN6oIhEksKsjy1ZDNs2dtNT58GWRSJGwVZnlrn1dE34Ly4tyvqUkRkCAVZnlpPNPjr9FIkbhRkeVrSVENl2vTJpUgMKcjyVJlOccqcjD65FIkhBdk46JpLkXhSkI1DSzZDe8cxDh/RIIsicaIgGwc1+IvEU1kFWTFGiM3VqkEWRWKprIKsGCPE5ppbV0399EoFmUjMlFWQFdvgIIsaLVYkXhRk4xQEWScDAxpkUSQuFGTj1JKto7unn5cPHY26FBEJKcjGqXWexiYTiRsF2Tgtn6vRYkXiRkE2TrXVFSxqmM7G3ToiE4kLBdkEtGbrdM2lSIwoyCagNZth675ujvX2R12KiKAgm5CWbIb+AWfzHg2yKBIHCrIJ0KVKIvGiIJuAxY0zqKpIqYe/SEwoyCagIp1i2ZxaHZGJxISCbIJas3UKMpGYUJBNUGs2w97O4xzo7om6FJEpT0E2QS0aZFEkNhRkE3TimkuN4S8SOQXZBM2uraahpko9/EViQEE2QWZGy9yMrrkUiQEF2SS0zsvwvAZZFImcgmwSWrMZjvb289KBI1GXIjKlKcgmoUWXKonEgoJsEpbPrcVMXTBEoqYgm4QZVRWc3DBDn1yKRKysgqzYN+gdTkt4VyURiU5ZBVmxb9A7nNZsHVv3d3O0R4MsikSlrIIsCq3ZDO7wwh4dlYlERUE2Sa9ec6kgE4mKgmySTm6sYVplStdcikRIQTZJ6ZSxfG6GTbvVBUMkKgqyAmiZq08uRaKkICuA1nl17OvqYW/n8ahLEZmSFGQF0Bo2+OuoTCQaCrICaNVosSKRUpAVQGNtNU211eqCIRIRBVmBtOpSJZHIKMgKpDWb4fndnfRrkEWRklOQFUhLNsPxvgG27e+OuhSRKUdBViCt4SCLOr0UKT0FWYEsm1tLymDjLn1yKVJqCrICmVaZZnFTjT65FImAgqyAWrMZNun2cCIlpyAroNZsHdv3H6H7eF/UpYhMKQqyAhocm+x5HZWJlFReQWZmf2BmdRb4JzNbb2ZvL3ZxSaNrLkWike8R2YfcvQN4OzALuBq4oWhVJdSiWTOYUZVWg79IieUbZBZ+/w3gO+7+bM40CaXCQRZ18bhIaeUbZOvM7McEQfaAmWWAgeKVlVyD11y661IlkVLJN8g+DFwHnOfuR4BK4INFqyrBWrMZDh7pZY8GWRQpmXyDrA3Y5O6HzOx3gS8BpbsLboK0hJcqqZ1MpHTyDbJvAkfM7Ezgs8CLwLeLVlWCvfrJpdrJREol3yDr86DR51LgJne/GcgUr6zkmlVTxdy6at0eTqSEKvJcrtPMrifodvEmM0sRtJPJMFqydTq1FCmhfI/IrgCOE/QnawcWAjcWraqEW5HNsHlPFz19+mBXpBTyCrIwvO4A6s3sEuCYu6uNbARnnzSLnv4Bntx5KOpSRKaEfC9Ruhx4FPgd4HJgjZm9p5iFJdkFSxowg4df3B91KSJTQr6nlv+DoA/Z+939GuB84I+LV1ayzaqpojVbxyNbFGQipZBvkKXcfU/O4/3jeO6U1NbcyLrtBzne1x91KSJlL98w+pGZPWBmHzCzDwA/BO4vXlnJt6q5geN9Azz+ktrJRIot38b+PwJuAc4Iv25x9y8Us7Cku2BJI2bo9FKkBPLtR4a73wPcU8Raykr9jEpOm1/Hwy/u5zMXRV2NSHkb9YjMzDrNrGOYr04z0zU4Y1i1pJHHdxziWK/ayUSKadQgc/eMu9cN85Vx97pSFGhmzeGotHeXYnuF1La0kZ6+Ada/dDDqUkTKWlE/eTSzW81sj5k9M2T6xWa2ycw2m9l1o63D3be4+4eLWWexnLekgZTBI+pPJlJUebeRTdBtwE3kjJRhZmngZuC/ATuBx8zsXiAN/MWQ539oSLePRKmbVsnpC+p5ZMuBqEsRKWtFDTJ3f8jMFg+ZfD6w2d23AJjZXcCl7v4XwCXFrCcKbc2N3PqLrRzt6Wd6VTrqckTKUrGPyIazANiR83gncMFIC5tZI/DnwNlmdn0YeMMtdy1wLcDcuXNZvXp1XsV0dXXlvexE1HT30dvv3Hrvak5rKkyQFbvmQktavaCaS6VgNbt7Ub+AxcAzOY/fA3wr5/HVBGOcFWyb5557rufrwQcfzHvZieg81uvN1//Qb/zRxoKts9g1F1rS6nVXzaUynpqBtT7C33wUlxm9DCzKebwwnFaWaqsreN2Ceh5Wx1iRookiyB4DlpnZEjOrAt4L3BtBHSXTtrSRJ3ccovt4X9SliJSlYne/uBN4GGgxs51m9mF37wM+CTwAbAC+78F9MsvWquZG+gacddvVn0ykGIr9qeWVI0y/nyl00fnKk2dRkTIe3rKfNy+fHXU5ImVHQ/GUQE11BWcumqmBFkWKpKyCzMzeZWa3HD4cv1turmpu4OmXD9OldjKRgiurIHP3/3D3a+vr66Mu5Ve0NTfRP+A8tk29/EUKrayCLM7OPXkWlWnT+GQiRaAgK5HpVWnOWjRTF5CLFIGCrITamht5+uXDdBzrjboUkbKiICuhVc2NDDisVTuZSEEpyEronJNnUZVOqRuGSIGVVZDFufsFwLTKNGefNFPXXYoUWFkFWZy7Xwxa1dzIs690cPio2slECqWsgiwJ2pY24g6PblU7mUihKMhK7KxFM6muUDuZSCEpyEpsWmWac06apY6xIgWkIItA29JGNrR3cOhIT9SliJQFBVkEBtvJdHclkcJQkEXgjIX1TKtM6fRSpEDKKsji3o9sUHVFmpUnNyjIRAqkrIIsCf3IBrUtbWRjeycHutVOJjJZZRVkSbKquQGANToqE5k0BVlEzlg4k+mVaV2uJFIACrKIVKZTrFys/mQihaAgi1Db0kae393Fvq7jUZcikmgKsgi1NTcC6KhMZJIUZBE6fUE9NVVpBZnIJCnIIlSZTnHekgZdQC4ySWUVZEnpEJurrbmRF/d2s6fjWNSliCRWWQVZkjrEDlo12E6m8clEJqysgiyJTptfR6a6QqeXIpOgIItYRTrF+Ut03aXIZCjIYmBVcyNb93XTfljtZCIToSCLgbal6k8mMhkKshhYMa+OumlqJxOZKAVZDKRTxvlLGnlkq4JMZCIUZDHRtrSR7fuP8Mqho1GXIpI4CrKY0HWXIhOnIIuJ1myGmTMq1U4mMgEKsphIpYwLljRooEWRCSirIEvitZa52pob2XnwKDsOHIm6FJFEKasgS+K1lrlWqT+ZyISUVZAl3fI5GRpqqnR6KTJOCrIYGWwnW7PlAO4edTkiiaEgi5m2pY28fOgoOw6oP5lIvhRkMTPYn+zhLfsirkQkORRkMXPKnFqaaqt4ZIsGWhTJl4IsZsyMC5obefjF/WonE8mTgiyG2pobae84xrb96k8mkg8FWQyt0nWXIuOiIIuhpbNrmJ2p1nWXInlSkMWQmdHW3MgjW9ROJpIPBVlMrWpuZE/ncbbs6466FJHYK6sgS/pF47kGx/HX6aXI2MoqyJJ+0XiuxY0zyNZNU4O/SB7KKsjKiZmxqrmBR3TdpciYFGQx1ra0kX1dx9m8pyvqUkRiTUEWY23NTYD6k4mMRUEWY4sapjO/fprGJxMZg4IsxsyMVUsbeWTLAQYG1E4mMhIFWcytam7kQHcPL6idTGRECrKYOzE+2Ysan0xkJAqymFvUMIOFs6arnUxkFAqyBFjV3MiarWonExmJgiwB2pobOXSkl43tnVGXIhJLCrIE0P0uRUanIEuABTOnc1LDDLWTiYxAQZYQbc2NrNmyn361k4n8CgVZQrQtbaTjWB8bdnVEXYpI7CjIEkLj+IuMTEGWENn6aSxpqtFAiyLDKKsgK6cRYoezqrmRR7ceYEDjk4m8RlkFWTmNEDucVc0NdB7vY3vHQNSliMRKWQVZuXv90iaq0inufr6Hvn6FmcggBVmCzM5U87XLTufZ/QPc8H83Rl2OSGwoyBLm8vMWcdFJFXzr51u5Z93OqMsRiYWKqAuQ8XtvaxXdFfVc/29Ps3ROLWctmhl1SSKR0hFZAlWkjJuvOoc5mWp+7ztr2dNxLOqSRCKlIEuohpoq/vGalXQc7eNjt6/jeF9/1CWJREZBlmAr5tXxl79zJutfOsSXf/Cs7n8pU5aCLOHeecY8PvXWU/je2h18++HtUZcjEgkFWRn4w4uWc9GKOXz1vuf4pcb2lylIQVYGUinjr644iyVNNfz+HevZceBI1CWJlJSCrExkplXyj9espH/A+ei313Kkpy/qkkRKRkFWRpY01fC37zuH53d38rn/86Qa/2XKUJCVmV9bPpvr3tHK/U+3c/ODm6MuR6QkFGRl6KNvauays+bzlz9+np88tzvqckSKTkFWhsyMG377DF63oJ7PfO8JNu/RbeSkvCnIytS0yjS3XHMu0yrTfPTb6zh8pDfqkkSKRkFWxubVT+fvf/ccdh48wqfuelx3YJKypSArcysXN/DVS0/noef38r9/pDHMpDxpGJ8p4MrzT+K5Vzr4h4e2sGJeHZedvSDqkkQKSkdkU8SX33Uq5y9p4Av3PMXTO8vz5iwydSnIpojKdIpvXnUOTbXVXPudteztPB51SSIFoyCbQhprq7nlmnM5eKSHj9++jp4+3cBEyoOCbIo5bX49N77nTNZuP8if3PuMLmOSslBWQVbuN+gtlHedOZ9PXLiUOx/dwe1rXoq6HJFJK6sgK/cb9BbSZ9/ewltb5/Cn9z7Lmi37oy5HZFLKKsgkf+mU8Y33nsVJjTP4xB3r2XlQY5hJcinIprC6cAyznv4Brv32Oo726AYmkkzqEDvFLZ1dy99ceTYfuu0x3n3TzzlvSQMrshla59XRks1QN60y6hJFxqQgE97SMoevX34mdz26gx8+tYvv5nwAsGDmdFbMy9CaDYJtxbwMixtrqEjrYF7iQ0EmAPzm2Qv5zbMX4u60dxxj465ONrR3sHFXJxvbO3hw094TF51XVaRYPreW1mwdrdkMK+YF3xtrqyPeC5mqFGTyGmbGvPrpzKufzlta55yYfryvn817uk4E28b2Tv7r+b3cvW7niWVmZ6pfE2yt2TqWzqmJYjdkilGQSV6qK9KcNr+e0+a/tmvLvq7jbGrvZMOuINw2tndw2y+3nbhqoCJlNE2Dhid/RmXaqEinqEwblekUFange2U6RUV68GejIpV69ed0zjKpnGXCaSkL6rDB79iJnwdZOMGGLDf4POO16wDj2d19HH+2Pe/Xx8Ze5FfqKbRn9vTRm7ARgQ8eKczVJQoymZSm2mqaTqnmDac0nZjW1z/Atv3dbAiP3tY8t42ZM6fR2+/0DQzQ2+d09fXR1+/09g/Q2z9A34DT2zdA74DT1z9Abzivb8CjG0ft8XXRbHcy1q+NuoJxuaq1issLsB4FmRRcRTrFKXMynDInw7vOnM/q6nYuvPC8Ca9vYMDpHRigr9/p63d6+gdOBKLjDF5l5XDikqvB6Hv1CqzXLjc4z8NHJ+aF3x9b+xgrV67Mq764XOW1du3avGuOiy3PrC/IehRkEnuplFGdSlNdwnfrnrr0r5xGx92+F9KcviBpNRfmNFufoYtI4inIRCTxFGQikngKMhFJPAWZiCSegkxEEk9BJiKJpyATkcRTkIlI4inIRCTxrBxvB2Zme4HteS7eBOwrYjnFkLSak1YvqOZSGU/NJ7v77OFmlGWQjYeZrXX3RF1pm7Sak1YvqOZSKVTNOrUUkcRTkIlI4inI4JaoC5iApNWctHpBNZdKQWqe8m1kIpJ8OiITkcSbskFmZheb2SYz22xm10Vdz1jMbJGZPWhmz5nZs2b2B1HXlC8zS5vZ42Z2X9S15MPMZprZ3Wa20cw2mFlb1DWNxsz+MHxPPGNmd5rZtKhrGsrMbjWzPWb2TM60BjP7f2b2Qvh91kTXPyWDzMzSwM3AO4BTgSvN7NRoqxpTH/BZdz8VWAX8fgJqHvQHwIaoixiHvwZ+5O6twJnEuHYzWwB8Gljp7qcDaeC90VY1rNuAi4dMuw74T3dfBvxn+HhCpmSQAecDm919i7v3AHcBl0Zc06jcfZe7rw9/7iT441oQbVVjM7OFwDuBb0VdSz7MrB54M/BPAO7e4+6Hoq1qTBXAdDOrAGYAr0Rcz69w94eAA0MmXwr8S/jzvwCXTXT9UzXIFgA7ch7vJAGhMMjMFgNnA2uirSQv3wA+DxTmBobFtwTYC/xzeDr8LTOL7V2G3f1l4C+Bl4BdwGF3/3G0VeVtrrvvCn9uB+ZOdEVTNcgSy8xqgXuAz7h7R9T1jMbMLgH2uHuSbhBZAZwDfNPdzwa6mcQpT7GF7UqXEgTwfKDGzH432qrGz4PuEyzT6gIAAAMgSURBVBPuQjFVg+xlYFHO44XhtFgzs0qCELvD3f816nry8Abg3Wa2jeD0/a1mdnu0JY1pJ7DT3QePdu8mCLa4ugjY6u573b0X+Ffg9RHXlK/dZjYPIPy+Z6IrmqpB9hiwzMyWmFkVQePovRHXNCozM4J2mw3u/vWo68mHu1/v7gvdfTHBa/xTd4/10YK7twM7zKwlnPQ24LkISxrLS8AqM5sRvkfeRow/nBjiXuD94c/vB/59oiuakjfodfc+M/sk8ADBpzy3uvuzEZc1ljcAVwNPm9kT4bQvuvv9EdZUrj4F3BH+k9sCfDDiekbk7mvM7G5gPcEn248Twx7+ZnYncCHQZGY7gT8BbgC+b2YfJhit5vIJr189+0Uk6abqqaWIlBEFmYgknoJMRBJPQSYiiacgE5HEU5BJSZnZL8Pvi83sfQVe9xeH25aUP3W/kEiY2YXA59z9knE8p8Ld+0aZ3+XutYWoT5JFR2RSUmbWFf54A/AmM3siHE8rbWY3mtljZvaUmf1euPyFZvYzM7uXsIe9mf3AzNaFY3BdG067gWAEiCfM7I7cbVngxnC8rqfN7Iqcda/OGXvsjrB3vCTMlOzZL7FwHTlHZGEgHXb388ysGviFmQ2O4nAOcLq7bw0ff8jdD5jZdOAxM7vH3a8zs0+6+1nDbOu3gLMIxhZrCp/zUDjvbOA0gqFvfkFwBcXPC7+7Ukw6IpO4eDtwTXj51RqgEVgWzns0J8QAPm1mTwKPEFz8v4zRvRG409373X038F/AeTnr3unuA8ATwOKC7I2UlI7IJC4M+JS7P/CaiUFbWveQxxcBbe5+xMxWA5MZ2vl4zs/96G8ikXREJlHpBDI5jx8APh4OVYSZLR9hQMN64GAYYq0Ew34P6h18/hA/A64I2+FmE4wA+2hB9kJiQf99JCpPAf3hKeJtBOPkLwbWhw3uexl+6OMfAR8zsw3AJoLTy0G3AE+Z2Xp3vypn+r8BbcCTBIP3fd7d28MglDKg7hcikng6tRSRxFOQiUjiKchEJPEUZCKSeAoyEUk8BZmIJJ6CTEQST0EmIon3/wHGJZZohJaoKgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "# PART 3 - Training a Convolutional Neural Network (CNN) with Haiku\n",
        "\n",
        "<hr>\n",
        "\n",
        "We have seen how to create and train a simple model using Haiku. Now we will use the built in models and blocks of Haiku to create and train a deep convolutional network.\n"
      ],
      "metadata": {
        "id": "2-ESLy53gDLp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1ndpYE50BpG"
      },
      "source": [
        "# **Feedback**\n",
        "\n",
        "Please provide feedback that we can use to improve our practicals in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIZvkhfRz9Jz",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a5a35f41-1cb4-4685-ac80-3028900c0ac0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<iframe \n",
              "\tsrc=\"https://forms.gle/bvLLPX74LMGrFefo9\",\n",
              "  width=\"80%\" \n",
              "\theight=\"1200px\" >\n",
              "\tLoading...\n",
              "</iframe>\n"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "# @title Generate Feedback Form. (Run Cell)\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\n",
        "    \"\"\"\n",
        "<iframe \n",
        "\tsrc=\"https://forms.gle/bvLLPX74LMGrFefo9\",\n",
        "  width=\"80%\" \n",
        "\theight=\"1200px\" >\n",
        "\tLoading...\n",
        "</iframe>\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oglV4kHMWnIN"
      },
      "source": [
        "<img src=\"https://baobab.deeplearningindaba.com/static/media/indaba-logo-dark.d5a6196d.png\" width=\"50%\" />"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
