# Khipu 2023 Practicals

| Topic ðŸ’¥ | Description ðŸ“˜ |
|:--- |----------------------------------------------------------|
[Introduction to ML using JAX](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/algebra_and_jax.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/Introduction_to_ML_using_JAX.ipynb) | In this tutorial, we will learn about JAX, a new machine learning framework that has taken deep learning research by storm! JAX is praised for its speed, and we will learn how to achieve these speedups, using core concepts in JAX, such as automatic differentiation (`grad`), parallelization (`pmap`), vectorization (`vmap`), just-in-time compilation (`jit`), and more.   | 
[Optimization and Haiku](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/optimization_and_haiku.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/Introduction_to_ML_using_JAX.ipynb) | Here you will learn the basic theory and algorithms of optimization, with emphasis on the methods used in Training Deep Learning. We will then introduce the Haiku optimization library, which greatly simplifies the impliementation of such algorithms.    | 
[Transformers and Attention](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/attention_and_transformers.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/attention_and_transformers.ipynb) | The transformer architecture, introduced in Vaswani et al. 2017's paper [Attention is All You Need](https://arxiv.org/abs/1706.03762?amp=1), has significantly impacted the deep learning field. It has arguably become the de-facto architecture for complex Natural Language Processing (NLP) tasks. It can also be applied in various domains reaching state-of-the-art performance, including computer vision and reinforcement learning. Transformers, as the title of the original paper implies, are almost entirely based on a concept known as attention. Attention allows models to "focus" on different parts of an input; while considering the entire context of the input versus an RNN, that operates on the data sequentially. In this practical, we will introduce attention in greater detail and build the entire transformer architecture block by block to see why it is such a robust and powerful architecture | 
[Graph Neural Networks](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/graph_neural_networks.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2022/blob/main/practicals/GNN_practical.ipynb) | In this tutorial, we will be learning about Graph Neural Networks (GNNs), a topic which has exploded in popularity in both research and industry. We will start with a refresher on graph theory, then dive into how GNNs work from a high level. Next we will cover some popular GNN implementations and see how they work in practice. | 
[Deep Generative Models](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/deep_generative_models.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/deep_generative_models.ipynb) | In this practical, we will investigate the fundamentals of generative modelling â€“ a machine learning framework that allows us to learn how to sample new unseen data points that match the distribution of our training dataset. Generative modelling, though a powerful and flexible frameworkâ€“which has provided many exciting advances in MLâ€“has its own challenges and limitations. This practical will walk you through such challenges and will illustrate how to solve them by implementing a Denoising Diffusion Model (a.k.a. a Score-Based Generative Model), which is the backbone of the recent and exciting [Dalle-2](https://openai.com/dall-e-2/) and [Imagen](https://imagen.research.google/) models that weâ€™ve all seen on [Twitter](https://twitter.com/search?q=%23dalle2%20%23imagen&src=typed_query). |
[Intro to Reinforcement Learning](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/reinforcement_learning.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/reinforcement_learning.ipynb) | In this tutorial, we will be learning about Reinforcement Learning, a type of Machine Learning where an agent learns to choose actions in an environment that lead to maximal reward in the long run. RL has seen tremendous success on a wide range of challenging problems such as learning to play complex video games like [Atari](https://www.deepmind.com/blog/agent57-outperforming-the-human-atari-benchmark), [StarCraft II](https://www.deepmind.com/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii) and [Dota II](https://openai.com/five/). In this introductory tutorial we will solve the classic [CartPole](https://www.gymlibrary.ml/environments/classic_control/cart_pole/) environment, where an agent must learn to balance a pole on a cart, using several different RL approaches. Along the way you will be introduced to some of the most important concepts and terminology in RL. | 
[Fairness In Machine Learning](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/fairness.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/fairness.ipynb) | In this tutorial, we will be learning about Reinforcement Learning, a type of Machine Learning where an agent learns to choose actions in an environment that lead to maximal reward in the long run. RL has seen tremendous success on a wide range of challenging problems such as learning to play complex video games like [Atari](https://www.deepmind.com/blog/agent57-outperforming-the-human-atari-benchmark), [StarCraft II](https://www.deepmind.com/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii) and [Dota II](https://openai.com/five/). In this introductory tutorial we will solve the classic [CartPole](https://www.gymlibrary.ml/environments/classic_control/cart_pole/) environment, where an agent must learn to balance a pole on a cart, using several different RL approaches. Along the way you will be introduced to some of the most important concepts and terminology in RL. | 

## Attribution

The above practicals are derived from the  [practicals developed for Indaba 2022](https://github.com/deep-learning-indaba/indaba-pracs-2022) with kind permission from the authors.


