# Khipu 2023 Practicals

| Topic ðŸ’¥ | Description ðŸ“˜ |
|:--- |----------------------------------------------------------|
[Introduction to ML using JAX](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/algebra_and_jax.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/algebra_and_jax.ipynb) | JAX is a new and exciting library for performing core tasks in machine learning algorithms such as tensor products or automatic gradient computation (autograd) while transparently exploiting the best available hardware resources and getting the most out of it via parallelization (`pmap`), vectorization (`vmap`), just-in-time compilation (`jit`), and more. **Note that JAX is a prerequisite for the other practicals in this repository; it is strongly recommented to start here**.  | 
[Optimization and Haiku](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/optimization_and_haiku.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/optimization_and_haiku.ipynb)) | Here you will learn the basic theory and algorithms of optimization, with emphasis on the methods used in Training Deep Learning. We will then introduce the Haiku optimization library, which greatly simplifies the impliementation of such algorithms.    | 
[Transformers and Attention](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/attention_and_transformers.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/attention_and_transformers.ipynb) | _Attention_ is a mechanism whereby a model can _focus_ on parts of the input data that are relevant to perform its inference. The _Transformer_ architecture [Vaswani et al. 2017](https://arxiv.org/abs/1706.03762?amp=1) provides an effective and versatile method to implement the concept of Attention in Deep Networks. Arguably, Transformes have become the de-facto architecture for complex Natural Language Processing (NLP) tasks, but can can also be applied in various domains reaching state-of-the-art performance, including computer vision and reinforcement learning. In this practical, we will introduce attention in greater detail and build the entire transformer architecture block by block. | 
[Graph Neural Networks](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/graph_neural_networks.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/graph_neural_networks.ipynb) | In this tutorial, we will be learning about Graph Neural Networks (GNNs), a topic which has exploded in popularity in both research and industry. We will start with a refresher on graph theory, then dive into how GNNs work from a high level. Next we will cover some popular GNN implementations and see how they work in practice. | 
[Deep Generative Models](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/deep_generative_models.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/deep_generative_models.ipynb) | Generative models are unsupervised methods which whose purpose is to generate new samples akin to those seen in the training dataset. Deep learning has taken these models to a new level with the introduction of architectures such as GANs, VAEs, Flow-based models and Diffusion Models. This practical will walk you through the challenges involved in developing an effective generative model for the particular case of  _Denoise Diffusion Models_ (a.k.a. a Score-Based Generative Model), the backbone of the recent and exciting [Dalle-2](https://openai.com/dall-e-2/) and [Imagen](https://imagen.research.google/) models that weâ€™ve all seen on [Twitter](https://twitter.com/search?q=%23dalle2%20%23imagen&src=typed_query). |
[Intro to Reinforcement Learning](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/reinforcement_learning.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/reinforcement_learning.ipynb) | In Reinforcement Learning (RL),  an _agent_ is trained to take the best actions in an environment so as to maximize a given reward in the long run. RL has seen tremendous success on a wide range of challenging problems such as learning to play complex video games like [Atari](https://www.deepmind.com/blog/agent57-outperforming-the-human-atari-benchmark), [StarCraft II](https://www.deepmind.com/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii) and [Dota II](https://openai.com/five/). In this introductory tutorial we will explore various RL approaches for solving the classic [CartPole](https://www.gymlibrary.ml/environments/classic_control/cart_pole/), an inverted pendulum system, where an agent must learn to balance a vertical pole by displacing the cart.| 
[Fairness In Machine Learning](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/fairness.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/khipu-ai/practicals-2023/blob/main/notebooks/fairness.ipynb) | In this tutorial, we will be learning about Reinforcement Learning, a type of Machine Learning where an agent learns to choose actions in an environment that lead to maximal reward in the long run. RL has seen tremendous success on a wide range of challenging problems such as learning to play complex video games like [Atari](https://www.deepmind.com/blog/agent57-outperforming-the-human-atari-benchmark), [StarCraft II](https://www.deepmind.com/blog/alphastar-mastering-the-real-time-strategy-game-starcraft-ii) and [Dota II](https://openai.com/five/). In this introductory tutorial we will solve the classic [CartPole](https://www.gymlibrary.ml/environments/classic_control/cart_pole/) environment, where an agent must learn to balance a pole on a cart, using several different RL approaches. Along the way you will be introduced to some of the most important concepts and terminology in RL. | 

## Attribution

The above practicals are derived from the  [practicals developed for Indaba 2022](https://github.com/deep-learning-indaba/indaba-pracs-2022) with kind permission from the authors.


